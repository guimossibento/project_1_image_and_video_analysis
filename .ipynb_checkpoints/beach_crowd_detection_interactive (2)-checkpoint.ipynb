{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beach Crowd Detection - Comprehensive Analytics Edition\n",
    "\n",
    "This notebook provides **extensive analytical tools** to understand beach images and select optimal detection techniques.\n",
    "\n",
    "**Key Features:**\n",
    "- **Otsu Threshold Analysis** - Automatic threshold detection\n",
    "- **Image Statistics** - Mean, std, contrast, entropy\n",
    "- **Color Distribution Analysis** - RGB, HSV, LAB histograms\n",
    "- **Texture Analysis** - Edge detection, local variance\n",
    "- **Segmentation Analysis** - Multiple methods comparison\n",
    "- **Recommendations** - Technique selection based on image properties\n",
    "- **Real-time parameter tuning** with unified interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T09:10:59.688899Z",
     "start_time": "2025-12-11T09:10:59.685793Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Libraries loaded successfully\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.colors import ListedColormap\n",
    "from scipy import ndimage\n",
    "from skimage import feature, filters\n",
    "from skimage.measure import shannon_entropy\n",
    "import os\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Optional, Tuple\n",
    "import warnings\n",
    "from IPython.display import display, clear_output, HTML\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual, VBox, HBox, Tab\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set matplotlib to display inline\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.max_open_warning'] = 0\n",
    "\n",
    "print(\"‚úì Libraries loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T09:10:59.705688Z",
     "start_time": "2025-12-11T09:10:59.701317Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Utility functions loaded\n"
     ]
    }
   ],
   "source": [
    "def adjust_gamma(image, gamma=0.4):\n",
    "    \"\"\"Apply gamma correction.\"\"\"\n",
    "    img = image.astype(np.float32) / 255.0\n",
    "    img = np.power(img, gamma)\n",
    "    return np.clip(img * 255.0, 0, 255).astype(np.uint8)\n",
    "\n",
    "\n",
    "def calculate_mae(detected_count: int, ground_truth_count: int) -> int:\n",
    "    \"\"\"Calculate Mean Absolute Error.\"\"\"\n",
    "    return abs(detected_count - ground_truth_count)\n",
    "\n",
    "\n",
    "def calculate_image_statistics(image):\n",
    "    \"\"\"Calculate comprehensive image statistics.\"\"\"\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY) if len(image.shape) == 3 else image\n",
    "    \n",
    "    stats = {\n",
    "        'mean': np.mean(gray),\n",
    "        'std': np.std(gray),\n",
    "        'min': np.min(gray),\n",
    "        'max': np.max(gray),\n",
    "        'median': np.median(gray),\n",
    "        'entropy': shannon_entropy(gray),\n",
    "        'contrast': np.max(gray) - np.min(gray),\n",
    "        'brightness_category': 'Dark' if np.mean(gray) < 85 else 'Medium' if np.mean(gray) < 170 else 'Bright',\n",
    "        'contrast_category': 'Low' if (np.max(gray) - np.min(gray)) < 100 else 'Medium' if (np.max(gray) - np.min(gray)) < 180 else 'High'\n",
    "    }\n",
    "    return stats\n",
    "\n",
    "\n",
    "def detect_edges(image):\n",
    "    \"\"\"Detect edges using multiple methods.\"\"\"\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY) if len(image.shape) == 3 else image\n",
    "    \n",
    "    # Canny edge detection\n",
    "    canny = cv2.Canny(gray, 50, 150)\n",
    "    \n",
    "    # Sobel edge detection\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)\n",
    "    sobel = np.sqrt(sobelx**2 + sobely**2)\n",
    "    sobel = np.uint8(255 * sobel / np.max(sobel))\n",
    "    \n",
    "    return {'canny': canny, 'sobel': sobel}\n",
    "\n",
    "\n",
    "def calculate_local_variance(image, window_size=15):\n",
    "    \"\"\"Calculate local variance to detect texture.\"\"\"\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY) if len(image.shape) == 3 else image\n",
    "    \n",
    "    # Calculate mean\n",
    "    mean = cv2.blur(gray.astype(float), (window_size, window_size))\n",
    "    \n",
    "    # Calculate variance\n",
    "    sqr_mean = cv2.blur((gray.astype(float))**2, (window_size, window_size))\n",
    "    variance = sqr_mean - mean**2\n",
    "    \n",
    "    return variance\n",
    "\n",
    "\n",
    "print(\"‚úì Utility functions loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Analytical Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T09:10:59.717700Z",
     "start_time": "2025-12-11T09:10:59.712536Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Analytical functions loaded\n"
     ]
    }
   ],
   "source": [
    "def analyze_color_spaces(image):\n",
    "    \"\"\"Analyze image in multiple color spaces.\"\"\"\n",
    "    # RGB\n",
    "    rgb_means = [np.mean(image[:,:,i]) for i in range(3)]\n",
    "    rgb_stds = [np.std(image[:,:,i]) for i in range(3)]\n",
    "    \n",
    "    # HSV\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "    hsv_means = [np.mean(hsv[:,:,i]) for i in range(3)]\n",
    "    hsv_stds = [np.std(hsv[:,:,i]) for i in range(3)]\n",
    "    \n",
    "    # LAB\n",
    "    lab = cv2.cvtColor(image, cv2.COLOR_RGB2LAB)\n",
    "    lab_means = [np.mean(lab[:,:,i]) for i in range(3)]\n",
    "    lab_stds = [np.std(lab[:,:,i]) for i in range(3)]\n",
    "    \n",
    "    return {\n",
    "        'rgb': {'means': rgb_means, 'stds': rgb_stds},\n",
    "        'hsv': {'means': hsv_means, 'stds': hsv_stds},\n",
    "        'lab': {'means': lab_means, 'stds': lab_stds}\n",
    "    }\n",
    "\n",
    "\n",
    "def otsu_analysis(image, roi_sand_only=False, hsv_s_max=50, hsv_v_min=100):\n",
    "    \"\"\"Perform Otsu threshold analysis.\"\"\"\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY) if len(image.shape) == 3 else image\n",
    "    \n",
    "    if roi_sand_only:\n",
    "        # Apply HSV filter to get sand regions\n",
    "        hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "        mask_sand = (hsv[:, :, 1] < hsv_s_max) & (hsv[:, :, 2] > hsv_v_min)\n",
    "        gray_roi = gray.copy()\n",
    "        gray_roi[~mask_sand] = 0\n",
    "        # Calculate Otsu on sand pixels only\n",
    "        sand_pixels = gray[mask_sand]\n",
    "        if len(sand_pixels) > 0:\n",
    "            otsu_threshold, _ = cv2.threshold(sand_pixels, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "        else:\n",
    "            otsu_threshold = 127\n",
    "        _, otsu_result = cv2.threshold(gray_roi, otsu_threshold, 255, cv2.THRESH_BINARY)\n",
    "    else:\n",
    "        # Global Otsu\n",
    "        otsu_threshold, otsu_result = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    \n",
    "    return {\n",
    "        'threshold': otsu_threshold,\n",
    "        'result': otsu_result,\n",
    "        'gray': gray\n",
    "    }\n",
    "\n",
    "\n",
    "def recommend_technique(image_stats, color_analysis):\n",
    "    \"\"\"Recommend detection technique based on image properties.\"\"\"\n",
    "    recommendations = []\n",
    "    \n",
    "    # Brightness recommendation\n",
    "    if image_stats['brightness_category'] == 'Dark':\n",
    "        recommendations.append(\"‚ö†Ô∏è Dark image: Use lower gamma (0.2-0.3) to brighten\")\n",
    "    elif image_stats['brightness_category'] == 'Bright':\n",
    "        recommendations.append(\"‚úì Bright image: Use standard gamma (0.4-0.6)\")\n",
    "    \n",
    "    # Contrast recommendation\n",
    "    if image_stats['contrast_category'] == 'Low':\n",
    "        recommendations.append(\"‚ö†Ô∏è Low contrast: Increase CLAHE clip limit (3.0-5.0)\")\n",
    "    else:\n",
    "        recommendations.append(\"‚úì Good contrast: Standard CLAHE (1.5-2.5)\")\n",
    "    \n",
    "    # HSV saturation analysis\n",
    "    hsv_sat_mean = color_analysis['hsv']['means'][1]\n",
    "    if hsv_sat_mean < 40:\n",
    "        recommendations.append(\"‚úì Low saturation: Good for sand detection (HSV_S_MAX = 50-70)\")\n",
    "    elif hsv_sat_mean > 80:\n",
    "        recommendations.append(\"‚ö†Ô∏è High saturation: Adjust HSV_S_MAX carefully (30-50)\")\n",
    "    \n",
    "    # HSV value analysis\n",
    "    hsv_val_mean = color_analysis['hsv']['means'][2]\n",
    "    if hsv_val_mean > 150:\n",
    "        recommendations.append(\"‚úì Bright scene: Good for detection (HSV_V_MIN = 100-120)\")\n",
    "    elif hsv_val_mean < 100:\n",
    "        recommendations.append(\"‚ö†Ô∏è Dark scene: Lower HSV_V_MIN (60-80)\")\n",
    "    \n",
    "    # Entropy (complexity)\n",
    "    if image_stats['entropy'] > 7:\n",
    "        recommendations.append(\"‚ö†Ô∏è High complexity: Use larger Gaussian blur (7-11)\")\n",
    "    else:\n",
    "        recommendations.append(\"‚úì Medium complexity: Standard blur (5-7)\")\n",
    "    \n",
    "    return recommendations\n",
    "\n",
    "\n",
    "print(\"‚úì Analytical functions loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Pipeline Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T09:10:59.727692Z",
     "start_time": "2025-12-11T09:10:59.722600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Processing functions loaded\n"
     ]
    }
   ],
   "source": [
    "def load_image(image_path):\n",
    "    \"\"\"Load image from path.\"\"\"\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        raise ValueError(f\"Could not load image: {image_path}\")\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "\n",
    "def apply_clahe(image, clip_limit=2.0):\n",
    "    \"\"\"Apply CLAHE enhancement.\"\"\"\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=(8, 8))\n",
    "    clahe_gray = clahe.apply(gray)\n",
    "    clahe_rgb = cv2.cvtColor(clahe_gray, cv2.COLOR_GRAY2RGB)\n",
    "    return clahe_rgb, clahe_gray\n",
    "\n",
    "\n",
    "def apply_preprocessing(\n",
    "    image,\n",
    "    gamma=0.4,\n",
    "    gaussian_size=5,\n",
    "    top_mask_percent=0.40,\n",
    "    hsv_s_max=50,\n",
    "    hsv_v_min=100,\n",
    "    morph_size=5,\n",
    "    adaptive_block_size=11,\n",
    "    adaptive_c=2,\n",
    "    use_otsu=False,\n",
    "):\n",
    "    # STEP 1: Top mask\n",
    "    h = image.shape[0]\n",
    "    mask_height = int(h * top_mask_percent)\n",
    "    top_masked = image.copy()\n",
    "    top_masked[:mask_height, :] = [128, 128, 128]\n",
    "\n",
    "    # STEP 2: Gamma\n",
    "    gamma_img = adjust_gamma(top_masked, gamma)\n",
    "\n",
    "    # STEP 3: Gaussian blur\n",
    "    if gaussian_size > 0:\n",
    "        blurred = cv2.GaussianBlur(gamma_img, (gaussian_size, gaussian_size), 0)\n",
    "    else:\n",
    "        blurred = gamma_img.copy()\n",
    "\n",
    "    # STEP 4: HSV sand mask\n",
    "    hsv = cv2.cvtColor(blurred, cv2.COLOR_RGB2HSV)\n",
    "    mask_sand = (hsv[:, :, 1] < hsv_s_max) & (hsv[:, :, 2] > hsv_v_min)\n",
    "\n",
    "    sand_mask_vis = np.zeros_like(blurred)\n",
    "    sand_mask_vis[mask_sand] = blurred[mask_sand]\n",
    "\n",
    "    non_sand_mask_vis = np.zeros_like(blurred)\n",
    "    non_sand_mask_vis[~mask_sand] = blurred[~mask_sand]\n",
    "\n",
    "    # STEP 5: remove sand (keep non-sand)\n",
    "    non_sand_only = blurred.copy()\n",
    "    non_sand_only[mask_sand] = [0, 0, 0]\n",
    "\n",
    "    # STEP 6: grayscale on non-sand\n",
    "    gray = cv2.cvtColor(non_sand_only, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # STEP 7: morphology (opening -> closing)\n",
    "    kernel = np.ones((morph_size, morph_size), np.uint8)\n",
    "    opened = cv2.morphologyEx(gray, cv2.MORPH_OPEN, kernel)\n",
    "    morph = cv2.morphologyEx(opened, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    # Optional HSV visualization (sand only)\n",
    "    hsv_filtered = blurred.copy()\n",
    "    hsv_filtered[~mask_sand] = [0, 0, 0]\n",
    "\n",
    "    # STEP 8: thresholding\n",
    "    if use_otsu:\n",
    "        sand_pixels = morph[mask_sand]\n",
    "        if len(sand_pixels) > 0 and np.max(sand_pixels) > 0:\n",
    "            otsu_threshold, _ = cv2.threshold(\n",
    "                sand_pixels, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU\n",
    "            )\n",
    "            _, binary = cv2.threshold(morph, otsu_threshold, 255, cv2.THRESH_BINARY)\n",
    "        else:\n",
    "            binary = np.zeros_like(morph)\n",
    "    else:\n",
    "        binary = cv2.adaptiveThreshold(\n",
    "            morph,\n",
    "            255,\n",
    "            cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "            cv2.THRESH_BINARY,\n",
    "            adaptive_block_size,\n",
    "            adaptive_c,\n",
    "        )\n",
    "\n",
    "    return {\n",
    "        \"gamma\": gamma_img,\n",
    "        \"blurred\": blurred,\n",
    "        \"masked\": top_masked,\n",
    "        \"sand_mask\": sand_mask_vis,\n",
    "        \"non_sand_mask\": non_sand_mask_vis,\n",
    "        \"hsv_filtered\": hsv_filtered,\n",
    "        \"gray\": gray,\n",
    "        \"opened\": opened,\n",
    "        \"morph\": morph,\n",
    "        \"binary\": binary,\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "def detect_blobs(binary_image, min_area=300, max_area=4500, \n",
    "                 min_circularity=0.2, min_convexity=0.5, min_inertia=0.1):\n",
    "    \"\"\"Detect blobs using SimpleBlobDetector with direct parameters.\"\"\"\n",
    "    params = cv2.SimpleBlobDetector_Params()\n",
    "    params.filterByArea = True\n",
    "    params.minArea = min_area\n",
    "    params.maxArea = max_area\n",
    "    params.filterByCircularity = True\n",
    "    params.minCircularity = min_circularity\n",
    "    params.filterByConvexity = True\n",
    "    params.minConvexity = min_convexity\n",
    "    params.filterByInertia = True\n",
    "    params.minInertiaRatio = min_inertia\n",
    "    params.filterByColor = False\n",
    "    \n",
    "    detector = cv2.SimpleBlobDetector_create(params)\n",
    "    keypoints = detector.detect(binary_image)\n",
    "    \n",
    "    detected_points = np.array([[kp.pt[0], kp.pt[1]] for kp in keypoints])\n",
    "    \n",
    "    return keypoints, detected_points\n",
    "\n",
    "\n",
    "print(\"‚úì Processing functions loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualization Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T09:10:59.746954Z",
     "start_time": "2025-12-11T09:10:59.734284Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Visualization functions loaded\n"
     ]
    }
   ],
   "source": [
    "def create_histogram_comparison(image, title=\"\"):\n",
    "    \"\"\"Create comprehensive histogram comparison.\"\"\"\n",
    "    fig = plt.figure(figsize=(20, 12))\n",
    "    gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n",
    "    \n",
    "    # RGB Histograms\n",
    "    colors = ['red', 'green', 'blue']\n",
    "    for i, (color, label) in enumerate(zip(colors, ['Red', 'Green', 'Blue'])):\n",
    "        ax = fig.add_subplot(gs[0, i])\n",
    "        hist = cv2.calcHist([image], [i], None, [256], [0, 256])\n",
    "        ax.plot(hist, color=color, linewidth=2)\n",
    "        ax.set_title(f'RGB - {label} Channel', fontweight='bold')\n",
    "        ax.set_xlabel('Intensity')\n",
    "        ax.set_ylabel('Frequency')\n",
    "        ax.grid(alpha=0.3)\n",
    "        # Add statistics\n",
    "        mean_val = np.mean(image[:,:,i])\n",
    "        ax.axvline(mean_val, color='black', linestyle='--', label=f'Mean: {mean_val:.1f}')\n",
    "        ax.legend()\n",
    "    \n",
    "    # HSV Histograms\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "    hsv_colors = ['red', 'green', 'blue']\n",
    "    hsv_labels = ['Hue', 'Saturation', 'Value']\n",
    "    for i, (color, label) in enumerate(zip(hsv_colors, hsv_labels)):\n",
    "        ax = fig.add_subplot(gs[1, i])\n",
    "        hist = cv2.calcHist([hsv], [i], None, [256], [0, 256])\n",
    "        ax.plot(hist, color=color, linewidth=2)\n",
    "        ax.set_title(f'HSV - {label}', fontweight='bold')\n",
    "        ax.set_xlabel('Value')\n",
    "        ax.set_ylabel('Frequency')\n",
    "        ax.grid(alpha=0.3)\n",
    "        # Add statistics\n",
    "        mean_val = np.mean(hsv[:,:,i])\n",
    "        ax.axvline(mean_val, color='black', linestyle='--', label=f'Mean: {mean_val:.1f}')\n",
    "        ax.legend()\n",
    "    \n",
    "    # LAB Histograms\n",
    "    lab = cv2.cvtColor(image, cv2.COLOR_RGB2LAB)\n",
    "    lab_colors = ['gray', 'green', 'red']\n",
    "    lab_labels = ['L (Lightness)', 'A (Green-Red)', 'B (Blue-Yellow)']\n",
    "    for i, (color, label) in enumerate(zip(lab_colors, lab_labels)):\n",
    "        ax = fig.add_subplot(gs[2, i])\n",
    "        hist = cv2.calcHist([lab], [i], None, [256], [0, 256])\n",
    "        ax.plot(hist, color=color, linewidth=2)\n",
    "        ax.set_title(f'LAB - {label}', fontweight='bold')\n",
    "        ax.set_xlabel('Value')\n",
    "        ax.set_ylabel('Frequency')\n",
    "        ax.grid(alpha=0.3)\n",
    "        # Add statistics\n",
    "        mean_val = np.mean(lab[:,:,i])\n",
    "        ax.axvline(mean_val, color='black', linestyle='--', label=f'Mean: {mean_val:.1f}')\n",
    "        ax.legend()\n",
    "    \n",
    "    if title:\n",
    "        fig.suptitle(title, fontsize=16, fontweight='bold')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def visualize_analytical_results(original, stats, edges, otsu_data, variance, recommendations):\n",
    "    \"\"\"Visualize comprehensive analytical results.\"\"\"\n",
    "    fig = plt.figure(figsize=(24, 16))\n",
    "    gs = fig.add_gridspec(3, 4, hspace=0.3, wspace=0.3)\n",
    "    \n",
    "    # Row 1: Original and basic processing\n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "    ax1.imshow(original)\n",
    "    ax1.set_title('Original Image', fontweight='bold')\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    ax2 = fig.add_subplot(gs[0, 1])\n",
    "    ax2.imshow(otsu_data['gray'], cmap='gray')\n",
    "    ax2.set_title(f'Grayscale (Mean: {stats[\"mean\"]:.1f})', fontweight='bold')\n",
    "    ax2.axis('off')\n",
    "    \n",
    "    ax3 = fig.add_subplot(gs[0, 2])\n",
    "    ax3.imshow(otsu_data['result'], cmap='gray')\n",
    "    ax3.set_title(f'Otsu Threshold ({otsu_data[\"threshold\"]:.0f})', fontweight='bold', color='blue')\n",
    "    ax3.axis('off')\n",
    "    \n",
    "    ax4 = fig.add_subplot(gs[0, 3])\n",
    "    ax4.imshow(edges['canny'], cmap='gray')\n",
    "    ax4.set_title('Canny Edges', fontweight='bold')\n",
    "    ax4.axis('off')\n",
    "    \n",
    "    # Row 2: Edge and texture analysis\n",
    "    ax5 = fig.add_subplot(gs[1, 0])\n",
    "    ax5.imshow(edges['sobel'], cmap='gray')\n",
    "    ax5.set_title('Sobel Edges', fontweight='bold')\n",
    "    ax5.axis('off')\n",
    "    \n",
    "    ax6 = fig.add_subplot(gs[1, 1])\n",
    "    ax6.imshow(variance, cmap='jet')\n",
    "    ax6.set_title('Local Variance (Texture)', fontweight='bold')\n",
    "    ax6.axis('off')\n",
    "    plt.colorbar(ax6.images[0], ax=ax6, fraction=0.046)\n",
    "    \n",
    "    # Histogram of grayscale with Otsu threshold marked\n",
    "    ax7 = fig.add_subplot(gs[1, 2])\n",
    "    hist = cv2.calcHist([otsu_data['gray']], [0], None, [256], [0, 256])\n",
    "    ax7.plot(hist, color='black', linewidth=2)\n",
    "    ax7.axvline(otsu_data['threshold'], color='red', linestyle='--', linewidth=2, label=f'Otsu: {otsu_data[\"threshold\"]:.0f}')\n",
    "    ax7.axvline(stats['mean'], color='blue', linestyle='--', linewidth=2, label=f'Mean: {stats[\"mean\"]:.0f}')\n",
    "    ax7.set_title('Intensity Distribution', fontweight='bold')\n",
    "    ax7.set_xlabel('Intensity')\n",
    "    ax7.set_ylabel('Frequency')\n",
    "    ax7.legend()\n",
    "    ax7.grid(alpha=0.3)\n",
    "    \n",
    "    # Statistics panel\n",
    "    ax8 = fig.add_subplot(gs[1, 3])\n",
    "    ax8.axis('off')\n",
    "    stats_text = f\"\"\"\n",
    "    IMAGE STATISTICS\n",
    "    {'=' * 40}\n",
    "    \n",
    "    Brightness: {stats['brightness_category']}\n",
    "    Mean: {stats['mean']:.2f}\n",
    "    Std Dev: {stats['std']:.2f}\n",
    "    \n",
    "    Contrast: {stats['contrast_category']}\n",
    "    Range: {stats['min']:.0f} - {stats['max']:.0f}\n",
    "    Contrast: {stats['contrast']:.0f}\n",
    "    \n",
    "    Complexity:\n",
    "    Entropy: {stats['entropy']:.2f}\n",
    "    Median: {stats['median']:.2f}\n",
    "    \n",
    "    Otsu Threshold: {otsu_data['threshold']:.0f}\n",
    "    \"\"\"\n",
    "    ax8.text(0.1, 0.5, stats_text, fontsize=11, family='monospace',\n",
    "             verticalalignment='center', bbox=dict(boxstyle='round', \n",
    "             facecolor='lightblue', alpha=0.8))\n",
    "    \n",
    "    # Row 3: Recommendations\n",
    "    ax9 = fig.add_subplot(gs[2, :])\n",
    "    ax9.axis('off')\n",
    "    \n",
    "    rec_text = \"\\n\".join([f\"{i+1}. {rec}\" for i, rec in enumerate(recommendations)])\n",
    "    recommendations_display = f\"\"\"\n",
    "    üéØ TECHNIQUE RECOMMENDATIONS\n",
    "    {'=' * 100}\n",
    "    \n",
    "    {rec_text}\n",
    "    \n",
    "    {'=' * 100}\n",
    "    üí° Tip: Use these insights to adjust parameters in the interactive section below!\n",
    "    \"\"\"\n",
    "    \n",
    "    ax9.text(0.05, 0.5, recommendations_display, fontsize=11, family='monospace',\n",
    "             verticalalignment='center', bbox=dict(boxstyle='round', \n",
    "             facecolor='lightgreen', alpha=0.8),\n",
    "             wrap=True)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def visualize_pipeline(original, steps, keypoints, ground_truth_points, \n",
    "                      detected_count, gt_count, mae, blob_params, use_otsu):\n",
    "    \"\"\"Visualize pipeline steps.\"\"\"\n",
    "    fig = plt.figure(figsize=(22, 14))\n",
    "    gs = fig.add_gridspec(3, 4, hspace=0.35, wspace=0.3)\n",
    "    \n",
    "    # Row 1\n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "    ax1.imshow(original)\n",
    "    ax1.set_title('1. Original', fontweight='bold', fontsize=10)\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    ax2 = fig.add_subplot(gs[0, 1])\n",
    "    ax2.imshow(steps['gamma'])\n",
    "    ax2.set_title('2. Gamma', fontweight='bold', fontsize=10)\n",
    "    ax2.axis('off')\n",
    "    \n",
    "    ax3 = fig.add_subplot(gs[0, 2])\n",
    "    ax3.imshow(steps['blurred'])\n",
    "    ax3.set_title('3. Blur', fontweight='bold', fontsize=10)\n",
    "    ax3.axis('off')\n",
    "    \n",
    "    ax4 = fig.add_subplot(gs[0, 3])\n",
    "    ax4.imshow(steps['masked'])\n",
    "    ax4.set_title('4. Top Mask', fontweight='bold', fontsize=10)\n",
    "    ax4.axis('off')\n",
    "    \n",
    "    # Row 2\n",
    "    ax5 = fig.add_subplot(gs[1, 0])\n",
    "    ax5.imshow(steps['sand_mask'])\n",
    "    ax5.set_title('5. Sand Mask', fontweight='bold', fontsize=10)\n",
    "    ax5.axis('off')\n",
    "    \n",
    "    ax6 = fig.add_subplot(gs[1, 1])\n",
    "    ax6.imshow(steps['non_sand_mask'])\n",
    "    ax6.set_title('6. Non-Sand', fontweight='bold', fontsize=10)\n",
    "    ax6.axis('off')\n",
    "    \n",
    "    ax7 = fig.add_subplot(gs[1, 2])\n",
    "    ax7.imshow(steps['gray'], cmap='gray')\n",
    "    ax7.set_title('7. Grayscale', fontweight='bold', fontsize=10)\n",
    "    ax7.axis('off')\n",
    "    \n",
    "    ax8 = fig.add_subplot(gs[1, 3])\n",
    "    ax8.imshow(steps['morph'], cmap='gray')\n",
    "    ax8.set_title('8. Morphology', fontweight='bold', fontsize=10)\n",
    "    ax8.axis('off')\n",
    "    \n",
    "    # Row 3\n",
    "    ax9 = fig.add_subplot(gs[2, 0])\n",
    "    ax9.imshow(steps['binary'], cmap='gray')\n",
    "    threshold_type = 'Otsu' if use_otsu else 'Adaptive'\n",
    "    ax9.set_title(f'9. Binary ({threshold_type})', fontweight='bold', fontsize=10, \n",
    "                  color='blue' if use_otsu else 'black')\n",
    "    ax9.axis('off')\n",
    "    \n",
    "    # Detection results\n",
    "    ax10 = fig.add_subplot(gs[2, 1:3])\n",
    "    result_img = original.copy()\n",
    "    \n",
    "    if len(keypoints) > 0:\n",
    "        for kp in keypoints:\n",
    "            x, y = int(kp.pt[0]), int(kp.pt[1])\n",
    "            cv2.circle(result_img, (x, y), 8, (0, 255, 0), 2)\n",
    "    \n",
    "    if len(ground_truth_points) > 0:\n",
    "        for pt in ground_truth_points:\n",
    "            x, y = int(pt[0]), int(pt[1])\n",
    "            cv2.circle(result_img, (x, y), 12, (255, 0, 0), 2)\n",
    "    \n",
    "    ax10.imshow(result_img)\n",
    "    ax10.set_title('10. Detection Results', fontweight='bold', fontsize=11)\n",
    "    ax10.axis('off')\n",
    "    \n",
    "    red_patch = mpatches.Patch(color='red', label=f'GT: {gt_count}')\n",
    "    green_patch = mpatches.Patch(color='green', label=f'Det: {detected_count}')\n",
    "    ax10.legend(handles=[red_patch, green_patch], loc='upper right')\n",
    "    \n",
    "    # Stats\n",
    "    ax11 = fig.add_subplot(gs[2, 3])\n",
    "    ax11.axis('off')\n",
    "    \n",
    "    stats_text = f\"\"\"\n",
    "    RESULTS\n",
    "    {'=' * 25}\n",
    "    \n",
    "    GT: {gt_count}\n",
    "    Detected: {detected_count}\n",
    "    MAE: {mae}\n",
    "    Error: {(mae/gt_count*100) if gt_count > 0 else 0:.1f}%\n",
    "    \n",
    "    BLOB PARAMS\n",
    "    {'=' * 25}\n",
    "    \n",
    "    Area: {blob_params['min_area']}-{blob_params['max_area']}\n",
    "    Circ: {blob_params['min_circularity']:.2f}\n",
    "    Conv: {blob_params['min_convexity']:.2f}\n",
    "    Inert: {blob_params['min_inertia']:.2f}\n",
    "    \"\"\"\n",
    "    \n",
    "    ax11.text(0.05, 0.5, stats_text, fontsize=9, family='monospace',\n",
    "              verticalalignment='center', bbox=dict(boxstyle='round', \n",
    "              facecolor='wheat', alpha=0.5))\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "print(\"‚úì Visualization functions loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Load Ground Truth & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T09:10:59.757517Z",
     "start_time": "2025-12-11T09:10:59.752644Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Loaded 540 annotations\n",
      "‚úì Found 10 images\n"
     ]
    }
   ],
   "source": [
    "def load_annotations(annotations_path):\n",
    "    \"\"\"Load ground truth annotations.\"\"\"\n",
    "    if not os.path.exists(annotations_path):\n",
    "        print(f\"‚ö† Annotations file not found: {annotations_path}\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    for sep in [';', ',', '\\t']:\n",
    "        try:\n",
    "            df = pd.read_csv(annotations_path, sep=sep)\n",
    "            if 'file' in df.columns and 'x' in df.columns and 'y' in df.columns:\n",
    "                print(f\"‚úì Loaded {len(df)} annotations\")\n",
    "                return df\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    print(f\"‚ö† Could not parse annotations file\")\n",
    "    return pd.DataFrame()\n",
    "\n",
    "\n",
    "def get_ground_truth(annotations_df, image_name):\n",
    "    \"\"\"Get ground truth points for specific image.\"\"\"\n",
    "    if annotations_df.empty:\n",
    "        return np.array([])\n",
    "    \n",
    "    matches = annotations_df[\n",
    "        (annotations_df['file'] == image_name) |\n",
    "        (annotations_df['file'] == f\"{image_name}.jpg\") |\n",
    "        (annotations_df['file'] == f\"{image_name}.png\")\n",
    "    ]\n",
    "    \n",
    "    if len(matches) > 0:\n",
    "        return matches[['x', 'y']].values\n",
    "    return np.array([])\n",
    "\n",
    "\n",
    "# ==================== CONFIGURATION ====================\n",
    "IMAGES_DIR = 'images'  \n",
    "ANNOTATIONS_PATH = 'coordinates.csv'\n",
    "# ======================================================\n",
    "\n",
    "annotations_df = load_annotations(ANNOTATIONS_PATH)\n",
    "\n",
    "if os.path.exists(IMAGES_DIR):\n",
    "    image_files = sorted([f for f in os.listdir(IMAGES_DIR) \n",
    "                         if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
    "    print(f\"‚úì Found {len(image_files)} images\")\n",
    "else:\n",
    "    print(f\"‚ö† Images directory not found: {IMAGES_DIR}\")\n",
    "    image_files = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. üéØ COMPREHENSIVE ANALYTICAL INTERFACE\n",
    "\n",
    "**Select one image ‚Üí Get complete analytical perspective!**\n",
    "\n",
    "This provides:\n",
    "1. **Image Statistics** - brightness, contrast, entropy\n",
    "2. **Color Space Analysis** - RGB, HSV, LAB histograms with statistics\n",
    "3. **Otsu Threshold Analysis** - automatic threshold detection\n",
    "4. **Edge & Texture Analysis** - Canny, Sobel, local variance\n",
    "5. **Technique Recommendations** - based on image properties\n",
    "6. **Interactive Pipeline** - tune parameters with insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T09:10:59.771662Z",
     "start_time": "2025-12-11T09:10:59.765476Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Comprehensive analysis function loaded\n"
     ]
    }
   ],
   "source": [
    "def comprehensive_analysis(image_file, gamma, clahe_clip, gaussian_size,\n",
    "                          top_mask_percent, hsv_s_max, hsv_v_min, morph_size,\n",
    "                          adaptive_block_size, adaptive_c, use_otsu,\n",
    "                          min_area, max_area, min_circularity, min_convexity, min_inertia):\n",
    "    \"\"\"\n",
    "    Comprehensive analytical interface with all insights.\n",
    "    \"\"\"\n",
    "    \n",
    "    if not image_files:\n",
    "        print(\"‚ö† No images available.\")\n",
    "        return\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    # Load image\n",
    "    image_path = os.path.join(IMAGES_DIR, image_file)\n",
    "    original = load_image(image_path)\n",
    "    image_name = Path(image_file).stem\n",
    "    \n",
    "    # Header\n",
    "    display(HTML(f\"\"\"\n",
    "    <div style=\"background-color: #2c3e50; color: white; padding: 20px; border-radius: 10px; margin-bottom: 20px;\">\n",
    "        <h1 style=\"margin: 0;\">üìä Comprehensive Beach Image Analysis</h1>\n",
    "        <h2 style=\"margin: 10px 0 0 0; color: #3498db;\">{image_file}</h2>\n",
    "        <p style=\"margin: 10px 0 0 0; opacity: 0.9;\">Complete analytical perspective with technique recommendations</p>\n",
    "    </div>\n",
    "    \"\"\"))\n",
    "    \n",
    "    # # ========== SECTION 1: IMAGE STATISTICS ==========\n",
    "    # display(HTML(\"\"\"\n",
    "    # <div style=\"background-color: #e74c3c; color: white; padding: 12px; border-radius: 5px; margin: 20px 0 10px 0;\">\n",
    "    #     <h2 style=\"margin: 0;\">üìà Section 1: Image Statistics & Properties</h2>\n",
    "    # </div>\n",
    "    # \"\"\"))\n",
    "    \n",
    "    # stats = calculate_image_statistics(original)\n",
    "    # color_analysis = analyze_color_spaces(original)\n",
    "    \n",
    "    # print(\"\\n\" + \"=\"*80)\n",
    "    # print(\"IMAGE STATISTICS\")\n",
    "    # print(\"=\"*80)\n",
    "    # print(f\"Brightness Category: {stats['brightness_category']} (Mean: {stats['mean']:.2f})\")\n",
    "    # print(f\"Contrast Category: {stats['contrast_category']} (Range: {stats['contrast']:.0f})\")\n",
    "    # print(f\"Complexity (Entropy): {stats['entropy']:.2f}\")\n",
    "    # print(f\"Standard Deviation: {stats['std']:.2f}\")\n",
    "    # print(f\"Min/Max: {stats['min']:.0f} / {stats['max']:.0f}\")\n",
    "    # print(f\"Median: {stats['median']:.2f}\")\n",
    "    # print(\"\\n\" + \"=\"*80)\n",
    "    # print(\"COLOR SPACE ANALYSIS\")\n",
    "    # print(\"=\"*80)\n",
    "    # print(f\"RGB Means: R={color_analysis['rgb']['means'][0]:.1f}, \"\n",
    "    #       f\"G={color_analysis['rgb']['means'][1]:.1f}, B={color_analysis['rgb']['means'][2]:.1f}\")\n",
    "    # print(f\"HSV Means: H={color_analysis['hsv']['means'][0]:.1f}, \"\n",
    "    #       f\"S={color_analysis['hsv']['means'][1]:.1f}, V={color_analysis['hsv']['means'][2]:.1f}\")\n",
    "    # print(f\"LAB Means: L={color_analysis['lab']['means'][0]:.1f}, \"\n",
    "    #       f\"A={color_analysis['lab']['means'][1]:.1f}, B={color_analysis['lab']['means'][2]:.1f}\")\n",
    "    # print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    # # ========== SECTION 2: HISTOGRAM ANALYSIS ==========\n",
    "    # display(HTML(\"\"\"\n",
    "    # <div style=\"background-color: #9b59b6; color: white; padding: 12px; border-radius: 5px; margin: 20px 0 10px 0;\">\n",
    "    #     <h2 style=\"margin: 0;\">üìä Section 2: Multi-Space Histogram Analysis</h2>\n",
    "    #     <p style=\"margin: 5px 0 0 0; font-size: 14px;\">RGB, HSV, and LAB color spaces with statistical markers</p>\n",
    "    # </div>\n",
    "    # \"\"\"))\n",
    "    \n",
    "    # create_histogram_comparison(original, title=\"Color Space Histograms with Statistics\")\n",
    "    \n",
    "    # # ========== SECTION 3: OTSU & EDGE ANALYSIS ==========\n",
    "    # display(HTML(\"\"\"\n",
    "    # <div style=\"background-color: #3498db; color: white; padding: 12px; border-radius: 5px; margin: 20px 0 10px 0;\">\n",
    "    #     <h2 style=\"margin: 0;\">üîç Section 3: Otsu Threshold & Edge Analysis</h2>\n",
    "    #     <p style=\"margin: 5px 0 0 0; font-size: 14px;\">Automatic thresholding and texture detection</p>\n",
    "    # </div>\n",
    "    # \"\"\"))\n",
    "    \n",
    "    # otsu_data = otsu_analysis(original, roi_sand_only=True, hsv_s_max=hsv_s_max, hsv_v_min=hsv_v_min)\n",
    "    # edges = detect_edges(original)\n",
    "    # variance = calculate_local_variance(original)\n",
    "    # recommendations = recommend_technique(stats, color_analysis)\n",
    "    \n",
    "    # visualize_analytical_results(original, stats, edges, otsu_data, variance, recommendations)\n",
    "    \n",
    "    # ========== SECTION 4: PIPELINE VISUALIZATION ==========\n",
    "    display(HTML(\"\"\"\n",
    "    <div style=\"background-color: #27ae60; color: white; padding: 12px; border-radius: 5px; margin: 20px 0 10px 0;\">\n",
    "        <h2 style=\"margin: 0;\">‚öôÔ∏è Section 4: Detection Pipeline with Current Parameters</h2>\n",
    "    </div>\n",
    "    \"\"\"))\n",
    "    \n",
    "    # Get ground truth\n",
    "    ground_truth_points = get_ground_truth(annotations_df, image_name)\n",
    "    gt_count = len(ground_truth_points)\n",
    "    \n",
    "    # Apply CLAHE\n",
    "    clahe_rgb, _ = apply_clahe(original, clahe_clip)\n",
    "    \n",
    "    # Apply preprocessing\n",
    "    steps = apply_preprocessing(\n",
    "        clahe_rgb, gamma=gamma, gaussian_size=gaussian_size,\n",
    "        top_mask_percent=top_mask_percent, hsv_s_max=hsv_s_max,\n",
    "        hsv_v_min=hsv_v_min, morph_size=morph_size,\n",
    "        adaptive_block_size=adaptive_block_size, adaptive_c=adaptive_c,\n",
    "        use_otsu=use_otsu\n",
    "    )\n",
    "    \n",
    "    # Detect blobs\n",
    "    keypoints, detected_points = detect_blobs(\n",
    "        steps['binary'], \n",
    "        min_area=min_area, max_area=max_area,\n",
    "        min_circularity=min_circularity,\n",
    "        min_convexity=min_convexity,\n",
    "        min_inertia=min_inertia\n",
    "    )\n",
    "    detected_count = len(keypoints)\n",
    "    mae = calculate_mae(detected_count, gt_count)\n",
    "    \n",
    "    blob_params = {\n",
    "        'min_area': min_area, 'max_area': max_area,\n",
    "        'min_circularity': min_circularity,\n",
    "        'min_convexity': min_convexity,\n",
    "        'min_inertia': min_inertia\n",
    "    }\n",
    "    \n",
    "    visualize_pipeline(original, steps, keypoints, ground_truth_points,\n",
    "                      detected_count, gt_count, mae, blob_params, use_otsu)\n",
    "    \n",
    "    # ========== SUMMARY ==========\n",
    "    display(HTML(f\"\"\"\n",
    "    <div style=\"background-color: #f39c12; color: black; padding: 15px; border-radius: 5px; margin: 20px 0;\">\n",
    "        <h2 style=\"margin: 0 0 10px 0;\">‚úÖ Analysis Complete</h2>\n",
    "        <table style=\"width: 100%; color: black;\">\n",
    "            <tr><td><b>Ground Truth:</b></td><td>{gt_count} people</td></tr>\n",
    "            <tr><td><b>Detected:</b></td><td>{detected_count} people</td></tr>\n",
    "            <tr><td><b>MAE:</b></td><td>{mae} (Error: {(mae/gt_count*100) if gt_count > 0 else 0:.1f}%)</td></tr>\n",
    "        </table>\n",
    "    </div>\n",
    "    \"\"\"))\n",
    "\n",
    "\n",
    "print(\"‚úì Comprehensive analysis function loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. üéÆ INTERACTIVE CONTROL PANEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T09:11:02.650255Z",
     "start_time": "2025-12-11T09:10:59.777520Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"background-color: #34495e; color: white; padding: 20px; border-radius: 10px; margin-bottom: 20px;\">\n",
       "        <h1 style=\"margin: 0;\">üéØ Beach Crowd Detection - Analytics Edition</h1>\n",
       "        <p style=\"margin: 10px 0 0 0; font-size: 16px;\">Comprehensive image analysis with technique recommendations</p>\n",
       "        <ul style=\"margin: 10px 0 0 20px; font-size: 14px;\">\n",
       "            <li>‚úÖ Image statistics and color space analysis</li>\n",
       "            <li>‚úÖ Otsu threshold automatic detection</li>\n",
       "            <li>‚úÖ Edge and texture analysis</li>\n",
       "            <li>‚úÖ Technique recommendations based on image properties</li>\n",
       "            <li>‚úÖ Real-time parameter tuning</li>\n",
       "        </ul>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71d68924444d4c2a90bd3e7c840f158b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='üì∑ Image:', index=9, layout=Layout(width='550px'), options=('166028‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if image_files:\n",
    "    style = {'description_width': '200px'}\n",
    "    layout = widgets.Layout(width='550px')\n",
    "    \n",
    "    display(HTML(\"\"\"\n",
    "    <div style=\"background-color: #34495e; color: white; padding: 20px; border-radius: 10px; margin-bottom: 20px;\">\n",
    "        <h1 style=\"margin: 0;\">üéØ Beach Crowd Detection - Analytics Edition</h1>\n",
    "        <p style=\"margin: 10px 0 0 0; font-size: 16px;\">Comprehensive image analysis with technique recommendations</p>\n",
    "        <ul style=\"margin: 10px 0 0 20px; font-size: 14px;\">\n",
    "            <li>‚úÖ Image statistics and color space analysis</li>\n",
    "            <li>‚úÖ Otsu threshold automatic detection</li>\n",
    "            <li>‚úÖ Edge and texture analysis</li>\n",
    "            <li>‚úÖ Technique recommendations based on image properties</li>\n",
    "            <li>‚úÖ Real-time parameter tuning</li>\n",
    "        </ul>\n",
    "    </div>\n",
    "    \"\"\"))\n",
    "    \n",
    "    unified_interface = interactive(\n",
    "        comprehensive_analysis,\n",
    "        image_file=widgets.Dropdown(\n",
    "            options=image_files,\n",
    "            value=image_files[-1],\n",
    "            description='üì∑ Image:',\n",
    "            style=style, layout=layout\n",
    "        ),\n",
    "        # Brighten people/umbrellas a bit, keep contrast\n",
    "        gamma=widgets.FloatSlider(\n",
    "            value=0.40, min=0.3, max=1.0, step=0.05,\n",
    "            description='Gamma:', style=style, layout=layout, continuous_update=False\n",
    "        ),\n",
    "        # Slightly stronger CLAHE for local contrast\n",
    "        clahe_clip=widgets.FloatSlider(\n",
    "            value=2.5, min=1.0, max=4.0, step=0.5,\n",
    "            description='CLAHE Clip:', style=style, layout=layout, continuous_update=False\n",
    "        ),\n",
    "        gaussian_size=widgets.IntSlider(\n",
    "            value=5, min=3, max=15, step=2,\n",
    "            description='Gaussian Size:', style=style, layout=layout, continuous_update=False\n",
    "        ),\n",
    "        # Crop some top region (sky/buildings) but keep beach\n",
    "        top_mask_percent=widgets.FloatSlider(\n",
    "            value=0.40, min=0.0, max=0.8, step=0.05,\n",
    "            description='Top Mask %:', style=style, layout=layout, continuous_update=False\n",
    "        ),\n",
    "        # Sand: low saturation, high value\n",
    "        hsv_s_max=widgets.IntSlider(\n",
    "            value=35, min=20, max=120, step=5,\n",
    "            description='HSV S Max (Sand):', style=style, layout=layout, continuous_update=False\n",
    "        ),\n",
    "        hsv_v_min=widgets.IntSlider(\n",
    "            value=120, min=80, max=220, step=5,\n",
    "            description='HSV V Min (Sand):', style=style, layout=layout, continuous_update=False\n",
    "        ),\n",
    "        # Morphology tuned to person-scale blobs\n",
    "        morph_size=widgets.IntSlider(\n",
    "            value=5, min=3, max=15, step=2,\n",
    "            description='Morph Size:', style=style, layout=layout, continuous_update=False\n",
    "        ),\n",
    "        adaptive_block_size=widgets.IntSlider(\n",
    "            value=21, min=7, max=51, step=2,\n",
    "            description='Adaptive Block:', style=style, layout=layout, continuous_update=False\n",
    "        ),\n",
    "        adaptive_c=widgets.IntSlider(\n",
    "            value=1, min=-10, max=10, step=1,\n",
    "            description='Adaptive C:', style=style, layout=layout, continuous_update=False\n",
    "        ),\n",
    "        use_otsu=widgets.Checkbox(\n",
    "            value=False,\n",
    "            description='Use Otsu Threshold (Auto)',\n",
    "            style=style, layout=layout\n",
    "        ),\n",
    "        # Person-ish blob size at current resolution\n",
    "        min_area=widgets.IntSlider(\n",
    "            value=50, min=50, max=1500, step=10,\n",
    "            description='Blob Min Area:', style=style, layout=layout, continuous_update=False\n",
    "        ),\n",
    "        max_area=widgets.IntSlider(\n",
    "            value=2000, min=200, max=8000, step=50,\n",
    "            description='Blob Max Area:', style=style, layout=layout, continuous_update=False\n",
    "        ),\n",
    "        # People are not perfect circles, allow irregular\n",
    "        min_circularity=widgets.FloatSlider(\n",
    "            value=0.15, min=0.0, max=1.0, step=0.01,\n",
    "            description='Blob Min Circularity:', style=style, layout=layout, continuous_update=False\n",
    "        ),\n",
    "        # Your request: convexity ~ 0.3 to allow human shapes\n",
    "        min_convexity=widgets.FloatSlider(\n",
    "            value=0.35, min=0.0, max=1.0, step=0.01,\n",
    "            description='Blob Min Convexity:', style=style, layout=layout, continuous_update=False\n",
    "        ),\n",
    "        # Lower inertia so elongated bodies are allowed\n",
    "        min_inertia=widgets.FloatSlider(\n",
    "            value=0.03, min=0.0, max=1.0, step=0.01,\n",
    "            description='Blob Min Inertia:', style=style, layout=layout, continuous_update=False\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    display(unified_interface)\n",
    "else:\n",
    "    print(\"‚ö† No images found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. üìñ Analytics Guide\n",
    "\n",
    "### Understanding the Analytics:\n",
    "\n",
    "#### Image Statistics:\n",
    "- **Mean**: Average brightness (0-255). Lower = darker image\n",
    "- **Std Dev**: Variation in brightness. Higher = more varied\n",
    "- **Contrast**: Max - Min. Higher = more dynamic range\n",
    "- **Entropy**: Image complexity. Higher = more textured/complex\n",
    "\n",
    "#### Otsu Threshold:\n",
    "- **Automatic threshold selection** based on histogram analysis\n",
    "- Separates foreground (people) from background (sand)\n",
    "- Works best when histogram has two clear peaks\n",
    "- Compare with mean to see separation quality\n",
    "\n",
    "#### Edge Detection:\n",
    "- **Canny**: Detects strong edges (people outlines)\n",
    "- **Sobel**: Detects gradients (texture boundaries)\n",
    "- More edges = more complex scene\n",
    "\n",
    "#### Local Variance (Texture):\n",
    "- **High variance**: Textured regions (people, objects)\n",
    "- **Low variance**: Smooth regions (sand, sky)\n",
    "- Helps identify where people are likely to be\n",
    "\n",
    "### How to Use Analytics:\n",
    "\n",
    "1. **Start with image statistics** ‚Üí understand overall properties\n",
    "2. **Check histograms** ‚Üí see color distribution patterns\n",
    "3. **Review Otsu threshold** ‚Üí automatic separation point\n",
    "4. **Follow recommendations** ‚Üí adjust parameters accordingly\n",
    "5. **Experiment with Otsu vs Adaptive** ‚Üí see which works better\n",
    "6. **Fine-tune blob parameters** ‚Üí match detected people\n",
    "\n",
    "### Otsu vs Adaptive Thresholding:\n",
    "\n",
    "**Otsu (Automatic)**:\n",
    "- ‚úì No manual tuning needed\n",
    "- ‚úì Works well for bimodal histograms\n",
    "- ‚úì Fast and consistent\n",
    "- ‚úó Single global threshold\n",
    "- ‚úó Sensitive to lighting variations\n",
    "\n",
    "**Adaptive (Local)**:\n",
    "- ‚úì Handles lighting variations\n",
    "- ‚úì Different threshold per region\n",
    "- ‚úì Better for complex scenes\n",
    "- ‚úó Requires parameter tuning\n",
    "- ‚úó Can be noisy\n",
    "\n",
    "### Technique Selection:\n",
    "\n",
    "**Use Otsu when:**\n",
    "- Image has uniform lighting\n",
    "- Clear separation between people and sand\n",
    "- Histogram shows two distinct peaks\n",
    "\n",
    "**Use Adaptive when:**\n",
    "- Variable lighting (shadows, sun spots)\n",
    "- Complex background patterns\n",
    "- Need local contrast handling"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
