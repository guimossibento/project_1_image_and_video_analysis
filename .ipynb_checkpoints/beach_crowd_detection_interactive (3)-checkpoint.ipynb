{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beach Crowd Detection - Sand Removal Approach\n",
    "\n",
    "**Simple and logical: Remove sand ‚Üí Keep people ‚Üí Detect blobs**\n",
    "\n",
    "**Core Principle:**\n",
    "- HSV mask identifies sand (low saturation + high brightness)\n",
    "- **REMOVE sand pixels** ‚Üí What remains is people/objects\n",
    "- **Sand mask IS the threshold** - no Otsu or Adaptive needed!\n",
    "- Apply blob detection on non-sand regions\n",
    "\n",
    "**Analytics Included:**\n",
    "- üìä Image statistics\n",
    "- üé® Color histograms (RGB, HSV, LAB)\n",
    "- üîç Edge detection & texture analysis\n",
    "- üìè Otsu simulation (reference only, to understand sand/non-sand separation)\n",
    "- üí° AI recommendations\n",
    "- ‚öôÔ∏è Pipeline visualization"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T10:17:15.232227Z",
     "start_time": "2025-12-11T10:17:13.749611Z"
    }
   },
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from scipy import ndimage\n",
    "from skimage.measure import shannon_entropy\n",
    "import os\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "from IPython.display import display, clear_output, HTML\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interactive\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.rcParams[\"figure.max_open_warning\"] = 0\n",
    "\n",
    "print(\"‚úì Libraries loaded\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Libraries loaded\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T10:17:15.246300Z",
     "start_time": "2025-12-11T10:17:15.237674Z"
    }
   },
   "source": [
    "def adjust_gamma(image, gamma=0.4):\n",
    "    img = image.astype(np.float32) / 255.0\n",
    "    img = np.power(img, gamma)\n",
    "    return np.clip(img * 255.0, 0, 255).astype(np.uint8)\n",
    "\n",
    "def calculate_mae(detected_count, ground_truth_count):\n",
    "    return abs(detected_count - ground_truth_count)\n",
    "\n",
    "def calculate_image_statistics(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY) if len(image.shape) == 3 else image\n",
    "    return {\n",
    "        'mean': np.mean(gray), 'std': np.std(gray), 'min': np.min(gray), 'max': np.max(gray),\n",
    "        'median': np.median(gray), 'entropy': shannon_entropy(gray),\n",
    "        'contrast': np.max(gray) - np.min(gray), 'q25': np.percentile(gray, 25), 'q75': np.percentile(gray, 75),\n",
    "        'brightness_cat': 'Dark' if np.mean(gray) < 85 else 'Medium' if np.mean(gray) < 170 else 'Bright',\n",
    "        'contrast_cat': 'Low' if (np.max(gray) - np.min(gray)) < 100 else 'Medium' if (np.max(gray) - np.min(gray)) < 180 else 'High'\n",
    "    }\n",
    "\n",
    "def analyze_color_spaces(image):\n",
    "    rgb_means = [np.mean(image[:,:,i]) for i in range(3)]\n",
    "    rgb_stds = [np.std(image[:,:,i]) for i in range(3)]\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "    hsv_means = [np.mean(hsv[:,:,i]) for i in range(3)]\n",
    "    hsv_stds = [np.std(hsv[:,:,i]) for i in range(3)]\n",
    "    lab = cv2.cvtColor(image, cv2.COLOR_RGB2LAB)\n",
    "    lab_means = [np.mean(lab[:,:,i]) for i in range(3)]\n",
    "    lab_stds = [np.std(lab[:,:,i]) for i in range(3)]\n",
    "    return {\n",
    "        'rgb': {'means': rgb_means, 'stds': rgb_stds},\n",
    "        'hsv': {'means': hsv_means, 'stds': hsv_stds},\n",
    "        'lab': {'means': lab_means, 'stds': lab_stds}\n",
    "    }\n",
    "\n",
    "def detect_edges(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY) if len(image.shape) == 3 else image\n",
    "    canny = cv2.Canny(gray, 50, 150)\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)\n",
    "    sobel = np.sqrt(sobelx**2 + sobely**2)\n",
    "    sobel = np.uint8(255 * sobel / np.max(sobel))\n",
    "    return {'canny': canny, 'sobel': sobel, 'edge_density': np.sum(canny > 0) / canny.size}\n",
    "\n",
    "def calculate_local_variance(image, window_size=15):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY) if len(image.shape) == 3 else image\n",
    "    mean = cv2.blur(gray.astype(float), (window_size, window_size))\n",
    "    sqr_mean = cv2.blur((gray.astype(float))**2, (window_size, window_size))\n",
    "    return sqr_mean - mean**2\n",
    "\n",
    "def simulate_otsu_threshold(image, roi_mask=None):\n",
    "    \"\"\"Otsu simulation for reference - shows sand/non-sand separation quality.\"\"\"\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY) if len(image.shape) == 3 else image\n",
    "    if roi_mask is not None and np.any(roi_mask):\n",
    "        pixels = gray[roi_mask]\n",
    "        threshold = cv2.threshold(pixels, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[0] if len(pixels) > 0 else 127\n",
    "    else:\n",
    "        threshold = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[0]\n",
    "    _, otsu_result = cv2.threshold(gray, threshold, 255, cv2.THRESH_BINARY)\n",
    "    return {'threshold': threshold, 'result': otsu_result, 'gray': gray}\n",
    "\n",
    "def recommend_techniques(stats, color_analysis, edges):\n",
    "    recs = []\n",
    "    # Brightness\n",
    "    if stats['brightness_cat'] == 'Dark':\n",
    "        recs.append(f\"‚ö†Ô∏è DARK IMAGE (mean={stats['mean']:.1f}): Use gamma=0.2-0.3\")\n",
    "    elif stats['brightness_cat'] == 'Bright':\n",
    "        recs.append(f\"‚úÖ BRIGHT IMAGE (mean={stats['mean']:.1f}): Use gamma=0.4-0.6\")\n",
    "    else:\n",
    "        recs.append(f\"‚úÖ MEDIUM BRIGHTNESS (mean={stats['mean']:.1f}): Use gamma=0.35-0.5\")\n",
    "    # Contrast\n",
    "    if stats['contrast_cat'] == 'Low':\n",
    "        recs.append(f\"‚ö†Ô∏è LOW CONTRAST ({stats['contrast']:.0f}): Increase CLAHE=3.0-5.0\")\n",
    "    else:\n",
    "        recs.append(f\"‚úÖ GOOD CONTRAST ({stats['contrast']:.0f}): Standard CLAHE=2.0-2.5\")\n",
    "    # HSV Saturation\n",
    "    sat_mean = color_analysis['hsv']['means'][1]\n",
    "    if sat_mean < 40:\n",
    "        recs.append(f\"‚úÖ LOW SATURATION (S={sat_mean:.1f}): Great for sand! HSV_S_MAX=55-70\")\n",
    "    elif sat_mean < 60:\n",
    "        recs.append(f\"‚úÖ MEDIUM SATURATION (S={sat_mean:.1f}): Good. HSV_S_MAX=45-60\")\n",
    "    else:\n",
    "        recs.append(f\"‚ö†Ô∏è HIGH SATURATION (S={sat_mean:.1f}): Careful. HSV_S_MAX=30-45\")\n",
    "    # HSV Value\n",
    "    val_mean = color_analysis['hsv']['means'][2]\n",
    "    if val_mean > 150:\n",
    "        recs.append(f\"‚úÖ BRIGHT SCENE (V={val_mean:.1f}): HSV_V_MIN=100-120\")\n",
    "    elif val_mean < 100:\n",
    "        recs.append(f\"‚ö†Ô∏è DARK SCENE (V={val_mean:.1f}): HSV_V_MIN=60-80\")\n",
    "    else:\n",
    "        recs.append(f\"‚úÖ MEDIUM VALUE (V={val_mean:.1f}): HSV_V_MIN=90-110\")\n",
    "    # Complexity\n",
    "    if stats['entropy'] > 7.0:\n",
    "        recs.append(f\"‚ö†Ô∏è HIGH COMPLEXITY (entropy={stats['entropy']:.2f}): blur=7-11, morph=7-9\")\n",
    "    elif stats['entropy'] > 6.0:\n",
    "        recs.append(f\"‚úÖ MEDIUM COMPLEXITY (entropy={stats['entropy']:.2f}): blur=5-7, morph=5\")\n",
    "    else:\n",
    "        recs.append(f\"‚úÖ LOW COMPLEXITY (entropy={stats['entropy']:.2f}): blur=3-5, morph=3\")\n",
    "    # Edge density\n",
    "    if edges['edge_density'] > 0.15:\n",
    "        recs.append(f\"‚ö†Ô∏è HIGH EDGE DENSITY ({edges['edge_density']:.2%}): Complex scene\")\n",
    "    else:\n",
    "        recs.append(f\"‚úÖ NORMAL EDGE DENSITY ({edges['edge_density']:.2%}): Standard OK\")\n",
    "    return recs\n",
    "\n",
    "print(\"‚úì Analysis functions loaded\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Analysis functions loaded\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T10:17:15.255038Z",
     "start_time": "2025-12-11T10:17:15.250953Z"
    }
   },
   "source": [
    "def load_image(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        raise ValueError(f\"Could not load: {image_path}\")\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "def apply_clahe(image, clip_limit=2.0):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=(8, 8))\n",
    "    clahe_gray = clahe.apply(gray)\n",
    "    clahe_rgb = cv2.cvtColor(clahe_gray, cv2.COLOR_GRAY2RGB)\n",
    "    return clahe_rgb, clahe_gray\n",
    "\n",
    "def apply_preprocessing(image, gamma=0.4, gaussian_size=5, top_mask_percent=0.40,\n",
    "                       hsv_s_max=50, hsv_v_min=100, morph_size=5):\n",
    "    \"\"\"\"Remove sand, keep non-sand. Sand mask IS the threshold!\"\"\"\n",
    "    # STEP 1: Top mask FIRST\n",
    "    h = image.shape[0]\n",
    "    mask_height = int(h * top_mask_percent)\n",
    "    top_masked = image.copy()\n",
    "    top_masked[:mask_height, :] = [128, 128, 128]\n",
    "    \n",
    "    # STEP 2: Gamma\n",
    "    gamma_img = adjust_gamma(top_masked, gamma)\n",
    "    \n",
    "    # STEP 3: Blur\n",
    "    if gaussian_size > 0:\n",
    "        blurred = cv2.GaussianBlur(gamma_img, (gaussian_size, gaussian_size), 0)\n",
    "    else:\n",
    "        blurred = gamma_img.copy()\n",
    "    \n",
    "    # STEP 4: HSV sand mask (THIS IS THE THRESHOLD!)\n",
    "    hsv = cv2.cvtColor(blurred, cv2.COLOR_RGB2HSV)\n",
    "    mask_sand = (hsv[:, :, 1] < hsv_s_max) & (hsv[:, :, 2] > hsv_v_min)\n",
    "    \n",
    "    # Visualizations\n",
    "    sand_mask_vis = np.zeros_like(blurred)\n",
    "    sand_mask_vis[mask_sand] = blurred[mask_sand]\n",
    "    \n",
    "    non_sand_mask_vis = np.zeros_like(blurred)\n",
    "    non_sand_mask_vis[~mask_sand] = blurred[~mask_sand]\n",
    "    \n",
    "    # STEP 5: REMOVE SAND, KEEP NON-SAND (people/objects)\n",
    "    non_sand_only = blurred.copy()\n",
    "    non_sand_only[mask_sand] = [0, 0, 0]  # Black out sand\n",
    "    \n",
    "    # STEP 6: Grayscale (only non-sand remains)\n",
    "    gray = cv2.cvtColor(non_sand_only, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # STEP 7: Morphology on non-sand\n",
    "    kernel = np.ones((morph_size, morph_size), np.uint8)\n",
    "    morph = cv2.morphologyEx(gray, cv2.MORPH_CLOSE, kernel)\n",
    "    \n",
    "    # STEP 8: Simple threshold (everything > 0 is non-sand)\n",
    "    _, binary = cv2.threshold(morph, 1, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    return {\n",
    "        'top_masked': top_masked,\n",
    "        'gamma': gamma_img,\n",
    "        'blurred': blurred,\n",
    "        'sand_mask': sand_mask_vis,\n",
    "        'non_sand_mask': non_sand_mask_vis,\n",
    "        'non_sand_only': non_sand_only,\n",
    "        'gray': gray,\n",
    "        'morph': morph,\n",
    "        'binary': binary,\n",
    "        'mask_sand': mask_sand\n",
    "    }\n",
    "\n",
    "def detect_blobs(binary_image, min_area=300, max_area=4500, \n",
    "                 min_circularity=0.2, min_convexity=0.5, min_inertia=0.1):\n",
    "    params = cv2.SimpleBlobDetector_Params()\n",
    "    params.filterByArea = True\n",
    "    params.minArea = min_area\n",
    "    params.maxArea = max_area\n",
    "    params.filterByCircularity = True\n",
    "    params.minCircularity = min_circularity\n",
    "    params.filterByConvexity = True\n",
    "    params.minConvexity = min_convexity\n",
    "    params.filterByInertia = True\n",
    "    params.minInertiaRatio = min_inertia\n",
    "    params.filterByColor = False\n",
    "    detector = cv2.SimpleBlobDetector_create(params)\n",
    "    keypoints = detector.detect(binary_image)\n",
    "    return keypoints, np.array([[kp.pt[0], kp.pt[1]] for kp in keypoints])\n",
    "\n",
    "print(\"‚úì Pipeline functions loaded\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Pipeline functions loaded\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T10:17:15.262644Z",
     "start_time": "2025-12-11T10:17:15.257879Z"
    }
   },
   "source": [
    "def load_annotations(path):\n",
    "    if not os.path.exists(path):\n",
    "        return pd.DataFrame()\n",
    "    for sep in [';', ',', '\\t']:\n",
    "        try:\n",
    "            df = pd.read_csv(path, sep=sep)\n",
    "            if all(c in df.columns for c in ['file', 'x', 'y']):\n",
    "                print(f\"‚úì Loaded {len(df)} annotations\")\n",
    "                return df\n",
    "        except:\n",
    "            continue\n",
    "    return pd.DataFrame()\n",
    "\n",
    "def get_ground_truth(df, name):\n",
    "    if df.empty:\n",
    "        return np.array([])\n",
    "    matches = df[(df['file'] == name) | (df['file'] == f\"{name}.jpg\") | (df['file'] == f\"{name}.png\")]\n",
    "    return matches[['x', 'y']].values if len(matches) > 0 else np.array([])\n",
    "\n",
    "IMAGES_DIR = 'images'\n",
    "ANNOTATIONS_PATH = 'coordinates.csv'\n",
    "annotations_df = load_annotations(ANNOTATIONS_PATH)\n",
    "image_files = sorted([f for f in os.listdir(IMAGES_DIR) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]) if os.path.exists(IMAGES_DIR) else []\n",
    "print(f\"‚úì Found {len(image_files)} images\" if image_files else \"‚ö† No images\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Loaded 540 annotations\n",
      "‚úì Found 10 images\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ COMPREHENSIVE ANALYSIS\n",
    "\n",
    "**Sections:**\n",
    "1. Statistics\n",
    "2. Color Histograms\n",
    "3. Edges & Texture\n",
    "4. Otsu Reference (shows separation quality)\n",
    "5. Recommendations\n",
    "6. Pipeline (sand removal approach)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T10:17:15.272046Z",
     "start_time": "2025-12-11T10:17:15.266450Z"
    }
   },
   "source": [
    "def comprehensive_analysis(\n",
    "    image_file,\n",
    "    gamma,\n",
    "    clahe_clip,\n",
    "    gaussian_size,\n",
    "    top_mask_percent,\n",
    "    hsv_s_max,\n",
    "    hsv_v_min,\n",
    "    morph_size,\n",
    "    min_area,\n",
    "    max_area,\n",
    "    min_circularity,\n",
    "    min_convexity,\n",
    "    min_inertia,\n",
    "):\n",
    "    if not image_files:\n",
    "        print(\"‚ö† No images\")\n",
    "        return\n",
    "\n",
    "    image_path = os.path.join(IMAGES_DIR, image_file)\n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"Image not found: {image_path}\")\n",
    "        return\n",
    "\n",
    "    # Load and analyze original image\n",
    "    original = load_image(image_path)\n",
    "    original_stats = calculate_image_statistics(original)\n",
    "    color_stats = analyze_color_spaces(original)\n",
    "    edges = detect_edges(original)\n",
    "    local_var_map = calculate_local_variance(original)\n",
    "    local_var_mean = float(np.mean(local_var_map))\n",
    "    otsu_stats = simulate_otsu_threshold(original)\n",
    "    recs = recommend_techniques(original_stats, edges)\n",
    "\n",
    "    # CLAHE + preprocessing (sand removal + masks)\n",
    "    clahe_rgb, clahe_gray = apply_clahe(original, clip_limit=clahe_clip)\n",
    "    pre = apply_preprocessing(\n",
    "        clahe_rgb,\n",
    "        gamma=gamma,\n",
    "        gaussian_size=gaussian_size,\n",
    "        top_mask_percent=top_mask_percent,\n",
    "        hsv_s_max=hsv_s_max,\n",
    "        hsv_v_min=hsv_v_min,\n",
    "        morph_size=morph_size,\n",
    "    )\n",
    "\n",
    "    # Blob detection on binary mask\n",
    "    keypoints, detected_pts = detect_blobs(\n",
    "        pre[\"binary\"],\n",
    "        min_area=min_area,\n",
    "        max_area=max_area,\n",
    "        min_circularity=min_circularity,\n",
    "        min_convexity=min_convexity,\n",
    "        min_inertia=min_inertia,\n",
    "    )\n",
    "    detected_count = len(detected_pts)\n",
    "\n",
    "    # Ground truth and MAE\n",
    "    gt_points = get_ground_truth(annotations_df, image_file)\n",
    "    gt_count = len(gt_points)\n",
    "    mae = calculate_mae(detected_count, gt_count) if gt_count > 0 else None\n",
    "\n",
    "    # ==== Plot grid ====\n",
    "    fig = plt.figure(figsize=(16, 9))\n",
    "    gs = GridSpec(2, 3, figure=fig)\n",
    "\n",
    "    ax0 = fig.add_subplot(gs[0, 0])\n",
    "    ax0.imshow(original)\n",
    "    ax0.set_title(\"Original\")\n",
    "    ax0.axis(\"off\")\n",
    "\n",
    "    ax1 = fig.add_subplot(gs[0, 1])\n",
    "    ax1.imshow(pre[\"gamma\"])\n",
    "    ax1.set_title(f\"Gamma corrected (Œ≥={gamma:.2f})\")\n",
    "    ax1.axis(\"off\")\n",
    "\n",
    "    ax2 = fig.add_subplot(gs[0, 2])\n",
    "    ax2.imshow(pre[\"sand_mask\"])\n",
    "    ax2.set_title(\"Sand mask (HSV + top cut)\")\n",
    "    ax2.axis(\"off\")\n",
    "\n",
    "    ax3 = fig.add_subplot(gs[1, 0])\n",
    "    ax3.imshow(pre[\"non_sand_only\"])\n",
    "    ax3.set_title(\"Scene without sand\")\n",
    "    ax3.axis(\"off\")\n",
    "\n",
    "    ax4 = fig.add_subplot(gs[1, 1])\n",
    "    ax4.imshow(pre[\"binary\"], cmap=\"gray\")\n",
    "    ax4.set_title(\"Binary mask used for blobs\")\n",
    "    ax4.axis(\"off\")\n",
    "\n",
    "    ax5 = fig.add_subplot(gs[1, 2])\n",
    "    ax5.imshow(original)\n",
    "    for kp in keypoints:\n",
    "        x, y = kp.pt\n",
    "        c = mpatches.Circle((x, y), radius=kp.size / 2, fill=False, linewidth=1.5)\n",
    "        ax5.add_patch(c)\n",
    "    if gt_count:\n",
    "        ax5.scatter(\n",
    "            gt_points[:, 0],\n",
    "            gt_points[:, 1],\n",
    "            s=30,\n",
    "            c=\"lime\",\n",
    "            marker=\"x\",\n",
    "            label=\"GT\",\n",
    "        )\n",
    "    ax5.set_title(f\"Detected blobs: {detected_count} (GT={gt_count})\")\n",
    "    ax5.axis(\"off\")\n",
    "\n",
    "    handles = []\n",
    "    if keypoints:\n",
    "        handles.append(\n",
    "            mpatches.Patch(edgecolor=\"yellow\", facecolor=\"none\", label=\"Blob\")\n",
    "        )\n",
    "    if gt_count:\n",
    "        handles.append(\n",
    "            mpatches.Patch(edgecolor=\"lime\", facecolor=\"none\", label=\"GT\")\n",
    "        )\n",
    "    if handles:\n",
    "        ax5.legend(handles=handles, loc=\"lower right\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # ==== Textual / HTML summary ====\n",
    "    stats_html = f\"\"\"\n",
    "    <ul>\n",
    "      <li><b>Brightness:</b> {original_stats['brightness_cat']} (mean={original_stats['mean']:.1f})</li>\n",
    "      <li><b>Contrast:</b> {original_stats['contrast_cat']} (Œî={original_stats['contrast']})</li>\n",
    "      <li><b>Entropy:</b> {original_stats['entropy']:.2f}</li>\n",
    "      <li><b>Local variance (mean):</b> {local_var_mean:.1f}</li>\n",
    "      <li><b>Edge density:</b> {edges['edge_density']:.2%}</li>\n",
    "      <li><b>Otsu threshold:</b> {otsu_stats['threshold']:.1f}</li>\n",
    "    </ul>\n",
    "    \"\"\"\n",
    "\n",
    "    if gt_count:\n",
    "        mae_html = (\n",
    "            f\"<p><b>Ground-truth people:</b> {gt_count} ¬∑ \"\n",
    "            f\"<b>Detected blobs:</b> {detected_count} ¬∑ \"\n",
    "            f\"<b>MAE:</b> {mae}</p>\"\n",
    "        )\n",
    "    else:\n",
    "        mae_html = (\n",
    "            f\"<p><b>Detected blobs:</b> {detected_count} \"\n",
    "            \"(no ground truth for this image)</p>\"\n",
    "        )\n",
    "\n",
    "    recs_html = \"<ul>\" + \"\".join(f\"<li>{r}</li>\" for r in recs) + \"</ul>\"\n",
    "\n",
    "    html = f\"\"\"\n",
    "    <div style=\"background:#2c3e50;color:white;padding:20px;border-radius:10px;margin-top:10px;\">\n",
    "      <h2 style=\"margin-top:0;\">Analysis for: {image_file}</h2>\n",
    "      {mae_html}\n",
    "      <h3>Image statistics</h3>\n",
    "      {stats_html}\n",
    "      <h3>Parameter suggestions</h3>\n",
    "      {recs_html}\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    display(HTML(html))\n",
    "\n",
    "    print(\"‚úì Comprehensive analysis updated\")\n"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T10:17:15.573918Z",
     "start_time": "2025-12-11T10:17:15.274575Z"
    }
   },
   "source": [
    "if image_files:\n",
    "    style = {\"description_width\": \"160px\"}\n",
    "    layout = widgets.Layout(width=\"340px\")\n",
    "\n",
    "    ui = interactive(\n",
    "        comprehensive_analysis,\n",
    "        image_file=widgets.Dropdown(\n",
    "            options=image_files,\n",
    "            description=\"Image:\",\n",
    "            style=style,\n",
    "            layout=layout,\n",
    "        ),\n",
    "        gamma=widgets.FloatSlider(\n",
    "            value=0.4, min=0.1, max=1.5, step=0.05,\n",
    "            description=\"Gamma:\", style=style, layout=layout,\n",
    "            continuous_update=False,\n",
    "        ),\n",
    "        clahe_clip=widgets.FloatSlider(\n",
    "            value=2.0, min=0.5, max=5.0, step=0.5,\n",
    "            description=\"CLAHE clip:\", style=style, layout=layout,\n",
    "            continuous_update=False,\n",
    "        ),\n",
    "        gaussian_size=widgets.IntSlider(\n",
    "            value=5, min=3, max=17, step=2,\n",
    "            description=\"Gaussian k:\", style=style, layout=layout,\n",
    "            continuous_update=False,\n",
    "        ),\n",
    "        top_mask_percent=widgets.FloatSlider(\n",
    "            value=0.40, min=0.0, max=0.8, step=0.05,\n",
    "            description=\"Top mask %:\", style=style, layout=layout,\n",
    "            continuous_update=False,\n",
    "        ),\n",
    "        hsv_s_max=widgets.IntSlider(\n",
    "            value=50, min=0, max=255, step=5,\n",
    "            description=\"HSV S max:\", style=style, layout=layout,\n",
    "            continuous_update=False,\n",
    "        ),\n",
    "        hsv_v_min=widgets.IntSlider(\n",
    "            value=100, min=0, max=255, step=5,\n",
    "            description=\"HSV V min:\", style=style, layout=layout,\n",
    "            continuous_update=False,\n",
    "        ),\n",
    "        morph_size=widgets.IntSlider(\n",
    "            value=5, min=1, max=15, step=2,\n",
    "            description=\"Morph size:\", style=style, layout=layout,\n",
    "            continuous_update=False,\n",
    "        ),\n",
    "        min_area=widgets.IntSlider(\n",
    "            value=300, min=10, max=10000, step=50,\n",
    "            description=\"Blob min area:\", style=style, layout=layout,\n",
    "            continuous_update=False,\n",
    "        ),\n",
    "        max_area=widgets.IntSlider(\n",
    "            value=4500, min=500, max=50000, step=100,\n",
    "            description=\"Blob max area:\", style=style, layout=layout,\n",
    "            continuous_update=False,\n",
    "        ),\n",
    "        min_circularity=widgets.FloatSlider(\n",
    "            value=0.2, min=0.0, max=1.0, step=0.05,\n",
    "            description=\"Blob min circ:\", style=style, layout=layout,\n",
    "            continuous_update=False,\n",
    "        ),\n",
    "        min_convexity=widgets.FloatSlider(\n",
    "            value=0.5, min=0.0, max=1.0, step=0.05,\n",
    "            description=\"Blob min conv:\", style=style, layout=layout,\n",
    "            continuous_update=False,\n",
    "        ),\n",
    "        min_inertia=widgets.FloatSlider(\n",
    "            value=0.1, min=0.0, max=1.0, step=0.05,\n",
    "            description=\"Blob min inertia:\", style=style, layout=layout,\n",
    "            continuous_update=False,\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    display(ui)\n",
    "else:\n",
    "    print(\"‚ö† No images found\")\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "interactive(children=(Dropdown(description='Image:', layout=Layout(width='340px'), options=('1660284000.jpg', ‚Ä¶"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e713cc95504c4c88b9cf13b2d6d15016"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 6
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 4,
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 }
}
