{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beach Crowd Detection - Adaptive Gamma Edition\n",
    "\n",
    "This notebook provides beach crowd detection using adaptive gamma correction that normalizes brightness across varying lighting conditions.\n",
    "\n",
    "**How adaptive gamma works:**\n",
    "```\n",
    "target_brightness = 160 (default)\n",
    "current_brightness = median(grayscale_image)\n",
    "gamma = log(target/255) / log(current/255)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from skimage.measure import shannon_entropy\n",
    "import os\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "from IPython.display import display, clear_output, HTML\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interactive\n",
    "import json\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.max_open_warning'] = 0\n",
    "\n",
    "print(\"‚úì Libraries loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_gamma(image, gamma=None, target_brightness=160.0):\n",
    "    \"\"\"Apply gamma correction - adaptive if gamma is None.\"\"\"\n",
    "    if gamma is not None:\n",
    "        img = image.astype(np.float32) / 255.0\n",
    "        img = np.power(img, gamma)\n",
    "        return np.clip(img * 255.0, 0, 255).astype(np.uint8)\n",
    "    \n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY) if len(image.shape) == 3 else image\n",
    "    current_brightness = np.clip(np.percentile(gray, 50), 1, 254)\n",
    "    target_brightness = np.clip(target_brightness, 1, 254)\n",
    "    \n",
    "    calculated_gamma = np.log(target_brightness / 255.0) / np.log(current_brightness / 255.0)\n",
    "    calculated_gamma = np.clip(calculated_gamma, 0.2, 3.0)\n",
    "    \n",
    "    img = image.astype(np.float32) / 255.0\n",
    "    img = np.power(img, calculated_gamma)\n",
    "    corrected = np.clip(img * 255.0, 0, 255).astype(np.uint8)\n",
    "    \n",
    "    return corrected, calculated_gamma\n",
    "\n",
    "\n",
    "def calculate_mae(detected_count, ground_truth_count):\n",
    "    return abs(detected_count - ground_truth_count)\n",
    "\n",
    "\n",
    "def calculate_image_statistics(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY) if len(image.shape) == 3 else image\n",
    "    return {\n",
    "        'mean': np.mean(gray),\n",
    "        'std': np.std(gray),\n",
    "        'min': np.min(gray),\n",
    "        'max': np.max(gray),\n",
    "        'median': np.median(gray),\n",
    "        'entropy': shannon_entropy(gray),\n",
    "        'contrast': np.max(gray) - np.min(gray),\n",
    "        'brightness_category': 'Dark' if np.mean(gray) < 85 else 'Medium' if np.mean(gray) < 170 else 'Bright',\n",
    "        'contrast_category': 'Low' if (np.max(gray) - np.min(gray)) < 100 else 'Medium' if (np.max(gray) - np.min(gray)) < 180 else 'High'\n",
    "    }\n",
    "\n",
    "\n",
    "LIMIT_POLYGON = None\n",
    "\n",
    "def load_limit_polygon(json_path):\n",
    "    with open(json_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    first_item = next(iter(data.values()))\n",
    "    regions = first_item[\"regions\"]\n",
    "    first_region = regions[next(iter(regions))]\n",
    "    shape = first_region[\"shape_attributes\"]\n",
    "    return np.array(list(zip(shape[\"all_points_x\"], shape[\"all_points_y\"])), dtype=np.int32)\n",
    "\n",
    "\n",
    "LIMIT_POLYGON = load_limit_polygon(\"limit_coordinates.json\")\n",
    "\n",
    "def apply_limit_mask(image, polygon=LIMIT_POLYGON):\n",
    "    if polygon is None:\n",
    "        return image\n",
    "    h, w = image.shape[:2]\n",
    "    mask = np.zeros((h, w), dtype=np.uint8)\n",
    "    cv2.fillPoly(mask, [polygon], 255)\n",
    "    return cv2.bitwise_and(image, image, mask=mask)\n",
    "\n",
    "\n",
    "print(\"‚úì Utility functions loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Analytical Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_color_spaces(image):\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "    lab = cv2.cvtColor(image, cv2.COLOR_RGB2LAB)\n",
    "    return {\n",
    "        'rgb': {'means': [np.mean(image[:,:,i]) for i in range(3)], 'stds': [np.std(image[:,:,i]) for i in range(3)]},\n",
    "        'hsv': {'means': [np.mean(hsv[:,:,i]) for i in range(3)], 'stds': [np.std(hsv[:,:,i]) for i in range(3)]},\n",
    "        'lab': {'means': [np.mean(lab[:,:,i]) for i in range(3)], 'stds': [np.std(lab[:,:,i]) for i in range(3)]}\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"‚úì Analytical functions loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Pipeline Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        raise ValueError(f\"Could not load image: {image_path}\")\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "\n",
    "def apply_clahe(image, clip_limit=2.0):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=(8, 8))\n",
    "    clahe_gray = clahe.apply(gray)\n",
    "    return cv2.cvtColor(clahe_gray, cv2.COLOR_GRAY2RGB), clahe_gray\n",
    "\n",
    "\n",
    "def apply_preprocessing(image, target_brightness=160.0, gamma=None, gaussian_size=5,\n",
    "                        top_mask_percent=0.40, hsv_s_max=50, hsv_v_min=100,\n",
    "                        morph_size=5, adaptive_block_size=11, adaptive_c=2):\n",
    "    top_masked = apply_limit_mask(image)\n",
    "    \n",
    "    gamma_result = adjust_gamma(top_masked, gamma=gamma, target_brightness=target_brightness)\n",
    "    if isinstance(gamma_result, tuple):\n",
    "        gamma_img, gamma_used = gamma_result\n",
    "    else:\n",
    "        gamma_img = gamma_result\n",
    "        gamma_used = gamma if gamma is not None else \"N/A\"\n",
    "\n",
    "    blurred = cv2.GaussianBlur(gamma_img, (gaussian_size, gaussian_size), 0) if gaussian_size > 0 else gamma_img.copy()\n",
    "\n",
    "    hsv = cv2.cvtColor(blurred, cv2.COLOR_RGB2HSV)\n",
    "    mask_sand = (hsv[:, :, 1] < hsv_s_max) & (hsv[:, :, 2] > hsv_v_min)\n",
    "\n",
    "    sand_mask_vis = np.zeros_like(blurred)\n",
    "    sand_mask_vis[mask_sand] = blurred[mask_sand]\n",
    "\n",
    "    non_sand_mask_vis = np.zeros_like(blurred)\n",
    "    non_sand_mask_vis[~mask_sand] = blurred[~mask_sand]\n",
    "\n",
    "    non_sand_only = blurred.copy()\n",
    "    non_sand_only[mask_sand] = [0, 0, 0]\n",
    "\n",
    "    gray = cv2.cvtColor(non_sand_only, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    kernel = np.ones((morph_size, morph_size), np.uint8)\n",
    "    opened = cv2.morphologyEx(gray, cv2.MORPH_OPEN, kernel)\n",
    "    morph = cv2.morphologyEx(opened, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    hsv_filtered = blurred.copy()\n",
    "    hsv_filtered[~mask_sand] = [0, 0, 0]\n",
    "\n",
    "    binary = cv2.adaptiveThreshold(morph, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                    cv2.THRESH_BINARY, adaptive_block_size, adaptive_c)\n",
    "\n",
    "    return {\n",
    "        \"gamma\": gamma_img, \"gamma_value\": gamma_used, \"blurred\": blurred,\n",
    "        \"masked\": top_masked, \"sand_mask\": sand_mask_vis, \"non_sand_mask\": non_sand_mask_vis,\n",
    "        \"hsv_filtered\": hsv_filtered, \"gray\": gray, \"opened\": opened, \"morph\": morph, \"binary\": binary\n",
    "    }\n",
    "\n",
    "\n",
    "def detect_blobs(binary_image, min_area=300, max_area=4500, \n",
    "                 min_circularity=0.2, min_convexity=0.5, min_inertia=0.1):\n",
    "    params = cv2.SimpleBlobDetector_Params()\n",
    "    params.filterByArea = True\n",
    "    params.minArea = min_area\n",
    "    params.maxArea = max_area\n",
    "    params.filterByCircularity = True\n",
    "    params.minCircularity = min_circularity\n",
    "    params.filterByConvexity = True\n",
    "    params.minConvexity = min_convexity\n",
    "    params.filterByInertia = True\n",
    "    params.minInertiaRatio = min_inertia\n",
    "    params.filterByColor = False\n",
    "    \n",
    "    detector = cv2.SimpleBlobDetector_create(params)\n",
    "    keypoints = detector.detect(binary_image)\n",
    "    detected_points = np.array([[kp.pt[0], kp.pt[1]] for kp in keypoints])\n",
    "    \n",
    "    return keypoints, detected_points\n",
    "\n",
    "\n",
    "print(\"‚úì Processing functions loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualization Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_pipeline(original, steps, keypoints, ground_truth_points, \n",
    "                       detected_count, gt_count, mae, blob_params):\n",
    "    fig = plt.figure(figsize=(22, 14))\n",
    "    gs = fig.add_gridspec(3, 4, hspace=0.35, wspace=0.3)\n",
    "    \n",
    "    # Row 1\n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "    ax1.imshow(original)\n",
    "    ax1.set_title('1. Original', fontweight='bold', fontsize=10)\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    ax2 = fig.add_subplot(gs[0, 1])\n",
    "    ax2.imshow(steps['gamma'])\n",
    "    gamma_val = steps.get('gamma_value', 'N/A')\n",
    "    gamma_title = f'2. Gamma (Œ≥={gamma_val:.3f})' if isinstance(gamma_val, float) else '2. Gamma'\n",
    "    ax2.set_title(gamma_title, fontweight='bold', fontsize=10)\n",
    "    ax2.axis('off')\n",
    "    \n",
    "    ax3 = fig.add_subplot(gs[0, 2])\n",
    "    ax3.imshow(steps['blurred'])\n",
    "    ax3.set_title('3. Blur', fontweight='bold', fontsize=10)\n",
    "    ax3.axis('off')\n",
    "    \n",
    "    ax4 = fig.add_subplot(gs[0, 3])\n",
    "    ax4.imshow(steps['masked'])\n",
    "    ax4.set_title('4. Masked Region', fontweight='bold', fontsize=10)\n",
    "    ax4.axis('off')\n",
    "    \n",
    "    # Row 2\n",
    "    ax5 = fig.add_subplot(gs[1, 0])\n",
    "    ax5.imshow(steps['sand_mask'])\n",
    "    ax5.set_title('5. Sand Mask', fontweight='bold', fontsize=10)\n",
    "    ax5.axis('off')\n",
    "    \n",
    "    ax6 = fig.add_subplot(gs[1, 1])\n",
    "    ax6.imshow(steps['non_sand_mask'])\n",
    "    ax6.set_title('6. Non-Sand', fontweight='bold', fontsize=10)\n",
    "    ax6.axis('off')\n",
    "    \n",
    "    ax7 = fig.add_subplot(gs[1, 2])\n",
    "    ax7.imshow(steps['gray'], cmap='gray')\n",
    "    ax7.set_title('7. Grayscale', fontweight='bold', fontsize=10)\n",
    "    ax7.axis('off')\n",
    "    \n",
    "    ax8 = fig.add_subplot(gs[1, 3])\n",
    "    ax8.imshow(steps['morph'], cmap='gray')\n",
    "    ax8.set_title('8. Morphology', fontweight='bold', fontsize=10)\n",
    "    ax8.axis('off')\n",
    "    \n",
    "    # Row 3\n",
    "    ax9 = fig.add_subplot(gs[2, 0])\n",
    "    ax9.imshow(steps['binary'], cmap='gray')\n",
    "    ax9.set_title('9. Binary (Adaptive)', fontweight='bold', fontsize=10, color='blue')\n",
    "    ax9.axis('off')\n",
    "    \n",
    "    # Detection results\n",
    "    ax10 = fig.add_subplot(gs[2, 1:3])\n",
    "    result_img = original.copy()\n",
    "    \n",
    "    if len(keypoints) > 0:\n",
    "        for kp in keypoints:\n",
    "            x, y = int(kp.pt[0]), int(kp.pt[1])\n",
    "            cv2.circle(result_img, (x, y), 8, (0, 255, 0), 2)\n",
    "    \n",
    "    if len(ground_truth_points) > 0:\n",
    "        for pt in ground_truth_points:\n",
    "            x, y = int(pt[0]), int(pt[1])\n",
    "            cv2.circle(result_img, (x, y), 12, (255, 0, 0), 2)\n",
    "    \n",
    "    ax10.imshow(result_img)\n",
    "    ax10.set_title('10. Detection Results', fontweight='bold', fontsize=11)\n",
    "    ax10.axis('off')\n",
    "    \n",
    "    red_patch = mpatches.Patch(color='red', label=f'GT: {gt_count}')\n",
    "    green_patch = mpatches.Patch(color='green', label=f'Det: {detected_count}')\n",
    "    ax10.legend(handles=[red_patch, green_patch], loc='upper right')\n",
    "    \n",
    "    # Stats\n",
    "    ax11 = fig.add_subplot(gs[2, 3])\n",
    "    ax11.axis('off')\n",
    "    \n",
    "    stats_text = f\"\"\"\n",
    "    RESULTS\n",
    "    {'=' * 25}\n",
    "    \n",
    "    GT: {gt_count}\n",
    "    Detected: {detected_count}\n",
    "    MAE: {mae}\n",
    "    Error: {(mae/gt_count*100) if gt_count > 0 else 0:.1f}%\n",
    "    \n",
    "    BLOB PARAMS\n",
    "    {'=' * 25}\n",
    "    \n",
    "    Area: {blob_params['min_area']}-{blob_params['max_area']}\n",
    "    Circ: {blob_params['min_circularity']:.2f}\n",
    "    Conv: {blob_params['min_convexity']:.2f}\n",
    "    Inert: {blob_params['min_inertia']:.2f}\n",
    "    \"\"\"\n",
    "    \n",
    "    ax11.text(0.05, 0.5, stats_text, fontsize=9, family='monospace',\n",
    "              verticalalignment='center', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "print(\"‚úì Visualization functions loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Load Ground Truth & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_annotations(annotations_path):\n",
    "    if not os.path.exists(annotations_path):\n",
    "        print(f\"‚ö† Annotations file not found: {annotations_path}\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    for sep in [';', ',', '\\t']:\n",
    "        try:\n",
    "            df = pd.read_csv(annotations_path, sep=sep)\n",
    "            if 'file' in df.columns and 'x' in df.columns and 'y' in df.columns:\n",
    "                print(f\"‚úì Loaded {len(df)} annotations\")\n",
    "                return df\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    print(f\"‚ö† Could not parse annotations file\")\n",
    "    return pd.DataFrame()\n",
    "\n",
    "\n",
    "def get_ground_truth(annotations_df, image_name):\n",
    "    if annotations_df.empty:\n",
    "        return np.array([])\n",
    "    \n",
    "    matches = annotations_df[\n",
    "        (annotations_df['file'] == image_name) |\n",
    "        (annotations_df['file'] == f\"{image_name}.jpg\") |\n",
    "        (annotations_df['file'] == f\"{image_name}.png\")\n",
    "    ]\n",
    "    \n",
    "    if len(matches) > 0:\n",
    "        return matches[['x', 'y']].values\n",
    "    return np.array([])\n",
    "\n",
    "\n",
    "# Configuration\n",
    "IMAGES_DIR = 'images'\n",
    "ANNOTATIONS_PATH = 'coordinates_human_annotated.csv'\n",
    "\n",
    "annotations_df = load_annotations(ANNOTATIONS_PATH)\n",
    "\n",
    "if os.path.exists(IMAGES_DIR):\n",
    "    image_files = sorted([f for f in os.listdir(IMAGES_DIR) \n",
    "                         if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
    "    print(f\"‚úì Found {len(image_files)} images\")\n",
    "else:\n",
    "    print(f\"‚ö† Images directory not found: {IMAGES_DIR}\")\n",
    "    image_files = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Comprehensive Analysis Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comprehensive_analysis(image_file, clahe_clip, gaussian_size, adaptive_block_size,\n",
    "                           adaptive_c, top_mask_percent, hsv_s_max, hsv_v_min,\n",
    "                           morph_size, min_area, max_area, min_circularity,\n",
    "                           min_convexity, min_inertia, target_brightness=160.0, clear=False):\n",
    "    if clear:\n",
    "        clear_output(wait=True)\n",
    "\n",
    "    image_path = os.path.join(IMAGES_DIR, image_file)\n",
    "    original = load_image(image_path)\n",
    "    image_name = Path(image_file).stem\n",
    "\n",
    "    display(HTML(f\"\"\"\n",
    "    <div style=\"background-color: #2c3e50; color: white; padding: 20px; border-radius: 10px; margin-bottom: 20px;\">\n",
    "        <h1 style=\"margin: 0;\">üìä Beach Crowd Detection</h1>\n",
    "        <h2 style=\"margin: 10px 0 0 0; color: #3498db;\">{image_file}</h2>\n",
    "    </div>\n",
    "    \"\"\"))\n",
    "\n",
    "    stats = calculate_image_statistics(original)\n",
    "    color_analysis = analyze_color_spaces(original)\n",
    "\n",
    "    display(HTML(\"\"\"\n",
    "    <div style=\"background-color: #27ae60; color: white; padding: 12px; border-radius: 5px; margin: 20px 0 10px 0;\">\n",
    "        <h2 style=\"margin: 0;\">‚öôÔ∏è Detection Pipeline</h2>\n",
    "    </div>\n",
    "    \"\"\"))\n",
    "\n",
    "    ground_truth_points = get_ground_truth(annotations_df, image_name)\n",
    "    gt_count = len(ground_truth_points)\n",
    "\n",
    "    clahe_rgb, _ = apply_clahe(original, clahe_clip)\n",
    "\n",
    "    steps = apply_preprocessing(\n",
    "        clahe_rgb,\n",
    "        target_brightness=target_brightness,\n",
    "        gaussian_size=gaussian_size,\n",
    "        top_mask_percent=top_mask_percent,\n",
    "        hsv_s_max=hsv_s_max,\n",
    "        hsv_v_min=hsv_v_min,\n",
    "        morph_size=morph_size,\n",
    "        adaptive_block_size=adaptive_block_size,\n",
    "        adaptive_c=adaptive_c,\n",
    "    )\n",
    "\n",
    "    keypoints, detected_points = detect_blobs(\n",
    "        steps['binary'],\n",
    "        min_area=min_area,\n",
    "        max_area=max_area,\n",
    "        min_circularity=min_circularity,\n",
    "        min_convexity=min_convexity,\n",
    "        min_inertia=min_inertia,\n",
    "    )\n",
    "    detected_count = len(keypoints)\n",
    "\n",
    "    mae = calculate_mae(detected_count, gt_count)\n",
    "    squared_error = (detected_count - gt_count) ** 2\n",
    "    error_percent = (mae / gt_count * 100) if gt_count > 0 else 0.0\n",
    "\n",
    "    blob_params = {\n",
    "        \"min_area\": min_area, \"max_area\": max_area,\n",
    "        \"min_circularity\": min_circularity, \"min_convexity\": min_convexity, \"min_inertia\": min_inertia\n",
    "    }\n",
    "\n",
    "    visualize_pipeline(original, steps, keypoints, ground_truth_points,\n",
    "                       detected_count, gt_count, mae, blob_params)\n",
    "\n",
    "    display(HTML(f\"\"\"\n",
    "    <div style=\"background-color: #f39c12; color: black; padding: 15px; border-radius: 5px; margin: 20px 0;\">\n",
    "        <h2 style=\"margin: 0 0 10px 0;\">‚úÖ Analysis Complete</h2>\n",
    "        <table style=\"width: 100%; color: black;\">\n",
    "            <tr><td><b>Ground Truth:</b></td><td>{gt_count} people</td></tr>\n",
    "            <tr><td><b>Detected:</b></td><td>{detected_count} people</td></tr>\n",
    "            <tr><td><b>MAE:</b></td><td>{mae} ({error_percent:.1f}% error)</td></tr>\n",
    "            <tr><td><b>Squared Error:</b></td><td>{squared_error}</td></tr>\n",
    "        </table>\n",
    "    </div>\n",
    "    \"\"\"))\n",
    "\n",
    "    return {\n",
    "        \"image_file\": image_file, \"image_name\": image_name,\n",
    "        \"ground_truth_count\": gt_count, \"detected_count\": detected_count,\n",
    "        \"mae\": mae, \"squared_error\": squared_error, \"error_percent\": error_percent,\n",
    "        \"blob_params\": blob_params, \"stats\": stats, \"color_analysis\": color_analysis,\n",
    "        \"ground_truth_points\": ground_truth_points, \"detected_points\": detected_points\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Interactive Control Panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if image_files:\n",
    "    style = {'description_width': '200px'}\n",
    "    layout = widgets.Layout(width='550px')\n",
    "    \n",
    "    display(HTML(\"\"\"\n",
    "    <div style=\"background-color: #34495e; color: white; padding: 20px; border-radius: 10px; margin-bottom: 20px;\">\n",
    "        <h1 style=\"margin: 0;\">üéØ Beach Crowd Detection - Interactive</h1>\n",
    "        <p style=\"margin: 10px 0 0 0;\">Real-time parameter tuning with adaptive gamma correction</p>\n",
    "    </div>\n",
    "    \"\"\"))\n",
    "    \n",
    "    unified_interface = interactive(\n",
    "        comprehensive_analysis,\n",
    "        image_file=widgets.Dropdown(options=image_files, value=image_files[-1],\n",
    "                                     description='üì∑ Image:', style=style, layout=layout),\n",
    "        clahe_clip=widgets.FloatSlider(value=2.5, min=1.0, max=4.0, step=0.5,\n",
    "                                        description='CLAHE Clip:', style=style, layout=layout, continuous_update=False),\n",
    "        gaussian_size=widgets.IntSlider(value=5, min=3, max=15, step=2,\n",
    "                                         description='Gaussian Size:', style=style, layout=layout, continuous_update=False),\n",
    "        top_mask_percent=widgets.FloatSlider(value=0.40, min=0.0, max=0.8, step=0.05,\n",
    "                                              description='Top Mask %:', style=style, layout=layout, continuous_update=False),\n",
    "        hsv_s_max=widgets.IntSlider(value=35, min=20, max=120, step=5,\n",
    "                                     description='HSV S Max (Sand):', style=style, layout=layout, continuous_update=False),\n",
    "        hsv_v_min=widgets.IntSlider(value=180, min=80, max=220, step=5,\n",
    "                                     description='HSV V Min (Sand):', style=style, layout=layout, continuous_update=False),\n",
    "        morph_size=widgets.IntSlider(value=5, min=3, max=15, step=2,\n",
    "                                      description='Morph Size:', style=style, layout=layout, continuous_update=False),\n",
    "        adaptive_block_size=widgets.IntSlider(value=21, min=7, max=51, step=2,\n",
    "                                               description='Adaptive Block:', style=style, layout=layout, continuous_update=False),\n",
    "        adaptive_c=widgets.IntSlider(value=1, min=-10, max=10, step=1,\n",
    "                                      description='Adaptive C:', style=style, layout=layout, continuous_update=False),\n",
    "        min_area=widgets.IntSlider(value=50, min=50, max=1600, step=10,\n",
    "                                    description='Blob Min Area:', style=style, layout=layout, continuous_update=False),\n",
    "        max_area=widgets.IntSlider(value=2000, min=200, max=8000, step=50,\n",
    "                                    description='Blob Max Area:', style=style, layout=layout, continuous_update=False),\n",
    "        min_circularity=widgets.FloatSlider(value=0.20, min=0.0, max=1.0, step=0.01,\n",
    "                                             description='Blob Min Circularity:', style=style, layout=layout, continuous_update=False),\n",
    "        min_convexity=widgets.FloatSlider(value=0.25, min=0.0, max=1.0, step=0.01,\n",
    "                                           description='Blob Min Convexity:', style=style, layout=layout, continuous_update=False),\n",
    "        min_inertia=widgets.FloatSlider(value=0.10, min=0.0, max=1.0, step=0.01,\n",
    "                                         description='Blob Min Inertia:', style=style, layout=layout, continuous_update=False)\n",
    "    )\n",
    "    \n",
    "    display(unified_interface)\n",
    "else:\n",
    "    print(\"‚ö† No images found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Batch Processing - All Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process all images with current parameters from the interactive UI\n",
    "p = unified_interface.kwargs  \n",
    "results = []\n",
    "\n",
    "for img_file in image_files:\n",
    "    print(f\"\\n=== Processing: {img_file} ===\")\n",
    "    res = comprehensive_analysis(\n",
    "        img_file,\n",
    "        target_brightness=p[\"target_brightness\"] if \"target_brightness\" in p else 160.0,\n",
    "        clahe_clip=p[\"clahe_clip\"],\n",
    "        gaussian_size=int(p[\"gaussian_size\"]),\n",
    "        adaptive_block_size=int(p[\"adaptive_block_size\"]),\n",
    "        adaptive_c=p[\"adaptive_c\"],\n",
    "        top_mask_percent=p[\"top_mask_percent\"],\n",
    "        hsv_s_max=p[\"hsv_s_max\"],\n",
    "        hsv_v_min=p[\"hsv_v_min\"],\n",
    "        morph_size=int(p[\"morph_size\"]),\n",
    "        min_area=int(p[\"min_area\"]),\n",
    "        max_area=int(p[\"max_area\"]),\n",
    "        min_circularity=p[\"min_circularity\"],\n",
    "        min_convexity=p[\"min_convexity\"],\n",
    "        min_inertia=p[\"min_inertia\"],\n",
    "        clear=False,\n",
    "    )\n",
    "    results.append(res)\n",
    "\n",
    "# Final report\n",
    "if results:\n",
    "    maes = np.array([r[\"mae\"] for r in results], dtype=float)\n",
    "    sq_errors = np.array([r[\"squared_error\"] for r in results], dtype=float)\n",
    "    error_percents = np.array([r[\"error_percent\"] for r in results], dtype=float)\n",
    "\n",
    "    display(HTML(f\"\"\"\n",
    "    <div style=\"background-color:#34495e; color:white; padding:20px; border-radius:10px; margin-top:25px;\">\n",
    "        <h2 style=\"margin-top:0;\">üìë Global Validation Report</h2>\n",
    "        <table style=\"width:100%; color:white;\">\n",
    "            <tr><td><b>Images evaluated:</b></td><td>{len(results)}</td></tr>\n",
    "            <tr><td><b>Mean MAE:</b></td><td>{maes.mean():.3f}</td></tr>\n",
    "            <tr><td><b>Mean Squared Error:</b></td><td>{sq_errors.mean():.3f}</td></tr>\n",
    "            <tr><td><b>Mean error percentage:</b></td><td>{error_percents.mean():.2f}%</td></tr>\n",
    "        </table>\n",
    "    </div>\n",
    "    \"\"\"))\n",
    "else:\n",
    "    print(\"No results to summarize.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
