{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive Beach Crowd Detection Pipeline\n",
    "\n",
    "This notebook provides an interactive interface to visualize and tune the beach crowd detection pipeline using ipywidgets.\n",
    "\n",
    "**Features:**\n",
    "- Direct blob parameter control (no levels)\n",
    "- **Dark threshold to remove shadows and dark objects**\n",
    "- Sand mask and non-sand mask visualization\n",
    "- HSV and LAB histogram analysis\n",
    "- Real-time parameter adjustment with sliders\n",
    "- Step-by-step visualization\n",
    "- Ground truth comparison\n",
    "- MAE calculation and display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T09:05:25.211982Z",
     "start_time": "2025-12-11T09:05:25.207971Z"
    }
   },
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.colors import ListedColormap\n",
    "import os\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Optional, Tuple\n",
    "import warnings\n",
    "from IPython.display import display, clear_output\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set matplotlib to display inline\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.max_open_warning'] = 0"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T09:05:25.220693Z",
     "start_time": "2025-12-11T09:05:25.216933Z"
    }
   },
   "source": [
    "def adjust_gamma(image, gamma=0.4):\n",
    "    \"\"\"Apply gamma correction.\"\"\"\n",
    "    img = image.astype(np.float32) / 255.0\n",
    "    img = np.power(img, gamma)\n",
    "    return np.clip(img * 255.0, 0, 255).astype(np.uint8)\n",
    "\n",
    "\n",
    "def calculate_mae(detected_count: int, ground_truth_count: int) -> int:\n",
    "    \"\"\"Calculate Mean Absolute Error.\"\"\"\n",
    "    return abs(detected_count - ground_truth_count)\n",
    "\n",
    "\n",
    "def create_hsv_histogram(image):\n",
    "    \"\"\"Create HSV histogram visualization.\"\"\"\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "    colors = ['red', 'green', 'blue']\n",
    "    labels = ['Hue', 'Saturation', 'Value']\n",
    "    \n",
    "    for i, (ax, color, label) in enumerate(zip(axes, colors, labels)):\n",
    "        hist = cv2.calcHist([hsv], [i], None, [256], [0, 256])\n",
    "        ax.plot(hist, color=color, linewidth=2)\n",
    "        ax.set_title(f'{label} Histogram', fontweight='bold')\n",
    "        ax.set_xlabel(label)\n",
    "        ax.set_ylabel('Frequency')\n",
    "        ax.grid(alpha=0.3)\n",
    "        ax.set_xlim([0, 256])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "def create_lab_histogram(image):\n",
    "    \"\"\"Create LAB histogram visualization.\"\"\"\n",
    "    lab = cv2.cvtColor(image, cv2.COLOR_RGB2LAB)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "    colors = ['gray', 'green', 'red']\n",
    "    labels = ['L (Lightness)', 'A (Green-Red)', 'B (Blue-Yellow)']\n",
    "    \n",
    "    for i, (ax, color, label) in enumerate(zip(axes, colors, labels)):\n",
    "        hist = cv2.calcHist([lab], [i], None, [256], [0, 256])\n",
    "        ax.plot(hist, color=color, linewidth=2)\n",
    "        ax.set_title(f'{label} Histogram', fontweight='bold')\n",
    "        ax.set_xlabel(label)\n",
    "        ax.set_ylabel('Frequency')\n",
    "        ax.grid(alpha=0.3)\n",
    "        ax.set_xlim([0, 256])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Pipeline Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T09:05:25.227735Z",
     "start_time": "2025-12-11T09:05:25.224665Z"
    }
   },
   "source": [
    "def apply_preprocessing(image, gamma=0.4, gaussian_size=5, top_mask_percent=0.40,\n",
    "                       hsv_s_max=50, hsv_v_min=100, morph_size=5,\n",
    "                       adaptive_block_size=11, adaptive_c=2, dark_threshold=30):\n",
    "    \"\"\"Apply all preprocessing steps.\"\"\"\n",
    "    # Gamma correction\n",
    "    gamma_img = adjust_gamma(image, gamma)\n",
    "    \n",
    "    # Gaussian blur\n",
    "    if gaussian_size > 0:\n",
    "        blurred = cv2.GaussianBlur(gamma_img, (gaussian_size, gaussian_size), 0)\n",
    "    else:\n",
    "        blurred = gamma_img.copy()\n",
    "    \n",
    "    # Mask top region\n",
    "    masked = blurred.copy()\n",
    "    h = masked.shape[0]\n",
    "    mask_height = int(h * top_mask_percent)\n",
    "    masked[:mask_height, :] = [128, 128, 128]\n",
    "    \n",
    "    # HSV filtering for sand detection\n",
    "    hsv = cv2.cvtColor(masked, cv2.COLOR_RGB2HSV)\n",
    "    mask_sand = (hsv[:, :, 1] < hsv_s_max) & (hsv[:, :, 2] > hsv_v_min)\n",
    "    \n",
    "    # Create sand mask visualization\n",
    "    sand_mask_vis = np.zeros_like(masked)\n",
    "    sand_mask_vis[mask_sand] = masked[mask_sand]\n",
    "    \n",
    "    # Create non-sand mask visualization\n",
    "    non_sand_mask_vis = np.zeros_like(masked)\n",
    "    non_sand_mask_vis[~mask_sand] = masked[~mask_sand]\n",
    "    \n",
    "    # Apply HSV filter\n",
    "    hsv_filtered = masked.copy()\n",
    "    hsv_filtered[~mask_sand] = [0, 0, 0]\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(hsv_filtered, cv2.COLOR_RGB2GRAY)\n",
    "    gray_before_dark = gray.copy()\n",
    "\n",
    "    # Remove dark areas (shadows, dark objects, non-people)\n",
    "    dark_mask = gray < dark_threshold\n",
    "    gray[dark_mask] = 0\n",
    "    \n",
    "    # Create dark removed visualization (show what was filtered)\n",
    "    dark_removed_vis = hsv_filtered.copy()\n",
    "    dark_removed_vis[dark_mask] = [255, 0, 0]  # Mark removed dark areas in red\n",
    "    \n",
    "    # Morphological operations\n",
    "    kernel = np.ones((morph_size, morph_size), np.uint8)\n",
    "    morph = cv2.morphologyEx(gray, cv2.MORPH_CLOSE, kernel)\n",
    "    \n",
    "    # Adaptive thresholding\n",
    "    binary = cv2.adaptiveThreshold(\n",
    "        morph, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "        cv2.THRESH_BINARY, adaptive_block_size, adaptive_c\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        'gamma': gamma_img,\n",
    "        'blurred': blurred,\n",
    "        'masked': masked,\n",
    "        'sand_mask': sand_mask_vis,\n",
    "        'non_sand_mask': non_sand_mask_vis,\n",
    "        'hsv_filtered': hsv_filtered,\n",
    "        'gray_before_dark': gray_before_dark,\n",
    "        'dark_removed_vis': dark_removed_vis,\n",
    "        'gray': gray,\n",
    "        'morph': morph,\n",
    "        'binary': binary\n",
    "    }\n",
    ""
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualization Functions"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T09:05:25.236441Z",
     "start_time": "2025-12-11T09:05:25.230735Z"
    }
   },
   "source": [
    "def visualize_pipeline(original, steps, keypoints, ground_truth_points, \n",
    "                      detected_count, gt_count, mae, blob_params):\n",
    "    \"\"\"Visualize all pipeline steps with ground truth comparison.\"\"\"\n",
    "    fig = plt.figure(figsize=(24, 18))\n",
    "    \n",
    "    # Create grid for 12 visualizations\n",
    "    gs = fig.add_gridspec(4, 4, hspace=0.35, wspace=0.3)\n",
    "    \n",
    "    # Row 1: Original processing steps\n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "    ax1.imshow(original)\n",
    "    ax1.set_title('1. Original Image', fontweight='bold', fontsize=10)\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    ax2 = fig.add_subplot(gs[0, 1])\n",
    "    ax2.imshow(steps['gamma'])\n",
    "    ax2.set_title('2. Gamma Correction', fontweight='bold', fontsize=10)\n",
    "    ax2.axis('off')\n",
    "    \n",
    "    ax3 = fig.add_subplot(gs[0, 2])\n",
    "    ax3.imshow(steps['blurred'])\n",
    "    ax3.set_title('3. Gaussian Blur', fontweight='bold', fontsize=10)\n",
    "    ax3.axis('off')\n",
    "    \n",
    "    ax4 = fig.add_subplot(gs[0, 3])\n",
    "    ax4.imshow(steps['masked'])\n",
    "    ax4.set_title('4. Top Mask', fontweight='bold', fontsize=10)\n",
    "    ax4.axis('off')\n",
    "    \n",
    "    # Row 2: Sand masks\n",
    "    ax5 = fig.add_subplot(gs[1, 0])\n",
    "    ax5.imshow(steps['sand_mask'])\n",
    "    ax5.set_title('5. Sand Mask (Detected)', fontweight='bold', fontsize=10)\n",
    "    ax5.axis('off')\n",
    "    \n",
    "    ax6 = fig.add_subplot(gs[1, 1])\n",
    "    ax6.imshow(steps['non_sand_mask'])\n",
    "    ax6.set_title('6. Non-Sand (Filtered)', fontweight='bold', fontsize=10)\n",
    "    ax6.axis('off')\n",
    "    \n",
    "    ax7 = fig.add_subplot(gs[1, 2])\n",
    "    ax7.imshow(steps['hsv_filtered'])\n",
    "    ax7.set_title('7. HSV Filtered', fontweight='bold', fontsize=10)\n",
    "    ax7.axis('off')\n",
    "    \n",
    "    ax8 = fig.add_subplot(gs[1, 3])\n",
    "    ax8.imshow(steps['gray_before_dark'], cmap='gray')\n",
    "    ax8.set_title('8. Grayscale (Before Dark)', fontweight='bold', fontsize=10)\n",
    "    ax8.axis('off')\n",
    "    \n",
    "    # Row 3: Dark threshold and processing\n",
    "    ax9 = fig.add_subplot(gs[2, 0])\n",
    "    ax9.imshow(steps['dark_removed_vis'])\n",
    "    ax9.set_title('9. Dark Removed (Red)', fontweight='bold', fontsize=10, color='red')\n",
    "    ax9.axis('off')\n",
    "    \n",
    "    ax10 = fig.add_subplot(gs[2, 1])\n",
    "    ax10.imshow(steps['gray'], cmap='gray')\n",
    "    ax10.set_title('10. Grayscale (After Dark)', fontweight='bold', fontsize=10)\n",
    "    ax10.axis('off')\n",
    "    \n",
    "    ax11 = fig.add_subplot(gs[2, 2])\n",
    "    ax11.imshow(steps['morph'], cmap='gray')\n",
    "    ax11.set_title('11. Morphological Ops', fontweight='bold', fontsize=10)\n",
    "    ax11.axis('off')\n",
    "    \n",
    "    ax12 = fig.add_subplot(gs[2, 3])\n",
    "    ax12.imshow(steps['binary'], cmap='gray')\n",
    "    ax12.set_title('12. Binary Threshold', fontweight='bold', fontsize=10)\n",
    "    ax12.axis('off')\n",
    "    \n",
    "    # Row 4: Detection results\n",
    "    ax13 = fig.add_subplot(gs[3, 0:2])\n",
    "    result_img = original.copy()\n",
    "    \n",
    "    # Draw detections\n",
    "    if len(keypoints) > 0:\n",
    "        for kp in keypoints:\n",
    "            x, y = int(kp.pt[0]), int(kp.pt[1])\n",
    "            cv2.circle(result_img, (x, y), 8, (0, 255, 0), 2)\n",
    "    \n",
    "    # Draw ground truth\n",
    "    if len(ground_truth_points) > 0:\n",
    "        for pt in ground_truth_points:\n",
    "            x, y = int(pt[0]), int(pt[1])\n",
    "            cv2.circle(result_img, (x, y), 12, (255, 0, 0), 2)\n",
    "    \n",
    "    ax13.imshow(result_img)\n",
    "    ax13.set_title('13. Detection Results (Red=GT, Green=Detected)', fontweight='bold', fontsize=11)\n",
    "    ax13.axis('off')\n",
    "    \n",
    "    # Add legend\n",
    "    red_patch = mpatches.Patch(color='red', label=f'Ground Truth: {gt_count}')\n",
    "    green_patch = mpatches.Patch(color='green', label=f'Detected: {detected_count}')\n",
    "    ax13.legend(handles=[red_patch, green_patch], loc='upper right', fontsize=10)\n",
    "    \n",
    "    # Statistics panel\n",
    "    ax14 = fig.add_subplot(gs[3, 2:])\n",
    "    ax14.axis('off')\n",
    "    \n",
    "    stats_text = f\"\"\"\n",
    "    DETECTION STATISTICS                    BLOB PARAMETERS\n",
    "    {'=' * 40}    {'=' * 40}\n",
    "    \n",
    "    Ground Truth: {gt_count:<10}              Min Area: {blob_params['min_area']}\n",
    "    Detected: {detected_count:<14}              Max Area: {blob_params['max_area']}\n",
    "    MAE: {mae:<19}              Min Circularity: {blob_params['min_circularity']:.3f}\n",
    "    Error %: {(mae / gt_count * 100) if gt_count > 0 else 0:.2f}%                           Min Convexity: {blob_params['min_convexity']:.3f}\n",
    "                                                  Min Inertia: {blob_params['min_inertia']:.3f}\n",
    "    \"\"\"\n",
    "    \n",
    "    ax14.text(0.05, 0.5, stats_text, fontsize=10, family='monospace',\n",
    "              verticalalignment='center', bbox=dict(boxstyle='round', \n",
    "              facecolor='wheat', alpha=0.5))\n",
    "    \n",
    "    plt.show()\n",
    ""
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Load Ground Truth Annotations"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T09:05:25.242485Z",
     "start_time": "2025-12-11T09:05:25.240057Z"
    }
   },
   "source": [
    "def load_annotations(annotations_path):\n",
    "    \"\"\"Load ground truth annotations from CSV.\"\"\"\n",
    "    if not os.path.exists(annotations_path):\n",
    "        print(f\"Warning: Annotations file not found: {annotations_path}\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    for sep in [';', ',', '\\t']:\n",
    "        try:\n",
    "            df = pd.read_csv(annotations_path, sep=sep)\n",
    "            if 'file' in df.columns and 'x' in df.columns and 'y' in df.columns:\n",
    "                print(f\"✓ Loaded {len(df)} annotations\")\n",
    "                return df\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    print(f\"Warning: Could not parse annotations file\")\n",
    "    return pd.DataFrame()\n",
    "\n",
    "\n",
    "def get_ground_truth(annotations_df, image_name):\n",
    "    \"\"\"Get ground truth points for specific image.\"\"\"\n",
    "    if annotations_df.empty:\n",
    "        return np.array([])\n",
    "    \n",
    "    # Try different filename formats\n",
    "    matches = annotations_df[\n",
    "        (annotations_df['file'] == image_name) |\n",
    "        (annotations_df['file'] == f\"{image_name}.jpg\") |\n",
    "        (annotations_df['file'] == f\"{image_name}.png\")\n",
    "    ]\n",
    "    \n",
    "    if len(matches) > 0:\n",
    "        return matches[['x', 'y']].values\n",
    "    return np.array([])"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Configuration & Data Loading\n",
    "\n",
    "**Update these paths to match your setup:**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T09:05:25.256069Z",
     "start_time": "2025-12-11T09:05:25.251826Z"
    }
   },
   "source": [
    "# Configuration\n",
    "IMAGES_DIR = 'images'  # Update this path\n",
    "ANNOTATIONS_PATH = 'coordinates.csv'  # Update this path\n",
    "\n",
    "# Load annotations\n",
    "annotations_df = load_annotations(ANNOTATIONS_PATH)\n",
    "\n",
    "# Get list of images\n",
    "if os.path.exists(IMAGES_DIR):\n",
    "    image_files = sorted([f for f in os.listdir(IMAGES_DIR) \n",
    "                         if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
    "    print(f\"✓ Found {len(image_files)} images\")\n",
    "    if image_files:\n",
    "        print(f\"  Images: {', '.join(image_files[:5])}{'...' if len(image_files) > 5 else ''}\")\n",
    "else:\n",
    "    print(f\"⚠ Images directory not found: {IMAGES_DIR}\")\n",
    "    image_files = []"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded 540 annotations\n",
      "✓ Found 10 images\n",
      "  Images: 1660284000.jpg, 1660287600.jpg, 1660291200.jpg, 1660294800.jpg, 1660298400.jpg...\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. HSV Histogram Analysis\n",
    "\n",
    "Analyze the HSV color space of the current image to better understand sand detection parameters."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T09:05:25.290491Z",
     "start_time": "2025-12-11T09:05:25.268668Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Select an image to analyze\n",
    "if image_files:\n",
    "    @interact\n",
    "    def show_hsv_histogram(image_file=widgets.Dropdown(options=image_files, description='Image:')):\n",
    "        image_path = os.path.join(IMAGES_DIR, image_file)\n",
    "        original = load_image(image_path)\n",
    "\n",
    "        print(\"HSV Histogram Analysis\")\n",
    "        print(\"=\" * 60)\n",
    "        print(\"Use this to understand the HSV values in your image:\")\n",
    "        print(\"- Hue: Color type (0-180 in OpenCV)\")\n",
    "        print(\"- Saturation: Color intensity (0-255)\")\n",
    "        print(\"- Value: Brightness (0-255)\")\n",
    "        print(\"\")\n",
    "        print(\"For sand detection:\")\n",
    "        print(\"- Low saturation (< HSV_S_MAX) = less colorful = sand-like\")\n",
    "        print(\"- High value (> HSV_V_MIN) = bright = sand-like\")\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "        fig = create_hsv_histogram(original)\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"⚠ No images available\")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "interactive(children=(Dropdown(description='Image:', options=('1660284000.jpg', '1660287600.jpg', '1660291200.…"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7aac2e9ec20246c0a34b1500fad141b2"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 9. LAB Histogram Analysis\n",
    "\n",
    "Analyze the LAB color space for additional insights."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T09:05:25.313963Z",
     "start_time": "2025-12-11T09:05:25.298280Z"
    }
   },
   "source": [
    "# Select an image to analyze\n",
    "if image_files:\n",
    "    @interact\n",
    "    def show_lab_histogram(image_file=widgets.Dropdown(options=image_files, description='Image:')):\n",
    "        image_path = os.path.join(IMAGES_DIR, image_file)\n",
    "        original = load_image(image_path)\n",
    "        \n",
    "        print(\"LAB Histogram Analysis\")\n",
    "        print(\"=\" * 60)\n",
    "        print(\"LAB color space separates:\")\n",
    "        print(\"- L: Lightness (0-255)\")\n",
    "        print(\"- A: Green-Red axis (0-255, 128=neutral)\")\n",
    "        print(\"- B: Blue-Yellow axis (0-255, 128=neutral)\")\n",
    "        print(\"\")\n",
    "        print(\"LAB is often better for detecting subtle color differences.\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        fig = create_lab_histogram(original)\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"⚠ No images available\")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "interactive(children=(Dropdown(description='Image:', options=('1660284000.jpg', '1660287600.jpg', '1660291200.…"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "23e1e2501c1a42329aaf2ef6a72e5998"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 7. Interactive Pipeline Visualizer\n",
    "\n",
    "Use the sliders below to adjust parameters and see results in real-time!"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T09:05:25.367943Z",
     "start_time": "2025-12-11T09:05:25.320586Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def interactive_pipeline(image_file, gamma, clahe_clip, gaussian_size,\n",
    "                        top_mask_percent, hsv_s_max, hsv_v_min, morph_size,\n",
    "                        adaptive_block_size, adaptive_c,\n",
    "                        min_area, max_area, min_circularity, min_convexity, min_inertia, dark_threshold):\n",
    "    \"\"\"Interactive pipeline function for ipywidgets.\"\"\"\n",
    "\n",
    "    if not image_files:\n",
    "        print(\"⚠ No images available. Please check IMAGES_DIR.\")\n",
    "        return\n",
    "\n",
    "    # Load image\n",
    "    image_path = os.path.join(IMAGES_DIR, image_file)\n",
    "    original = load_image(image_path)\n",
    "    image_name = Path(image_file).stem\n",
    "\n",
    "    # Get ground truth\n",
    "    ground_truth_points = get_ground_truth(annotations_df, image_name)\n",
    "    gt_count = len(ground_truth_points)\n",
    "\n",
    "    # Apply CLAHE\n",
    "    clahe_rgb, _ = apply_clahe(original, clahe_clip)\n",
    "\n",
    "    # Apply preprocessing\n",
    "    steps = apply_preprocessing(\n",
    "        clahe_rgb, gamma=gamma, gaussian_size=gaussian_size,\n",
    "        top_mask_percent=top_mask_percent, hsv_s_max=hsv_s_max,\n",
    "        hsv_v_min=hsv_v_min, morph_size=morph_size,\n",
    "        adaptive_block_size=adaptive_block_size, adaptive_c=adaptive_c,\n",
    "        dark_threshold=dark_threshold\n",
    "    )\n",
    "\n",
    "    # Detect blobs with direct parameters\n",
    "    keypoints, detected_points = detect_blobs(\n",
    "        steps['binary'],\n",
    "        min_area=min_area,\n",
    "        max_area=max_area,\n",
    "        min_circularity=min_circularity,\n",
    "        min_convexity=min_convexity,\n",
    "        min_inertia=min_inertia\n",
    "    )\n",
    "    detected_count = len(keypoints)\n",
    "\n",
    "    # Calculate MAE\n",
    "    mae = calculate_mae(detected_count, gt_count)\n",
    "\n",
    "    # Blob parameters for display\n",
    "    blob_params = {\n",
    "        'min_area': min_area,\n",
    "        'max_area': max_area,\n",
    "        'min_circularity': min_circularity,\n",
    "        'min_convexity': min_convexity,\n",
    "        'min_inertia': min_inertia\n",
    "    }\n",
    "\n",
    "    # Clear and visualize\n",
    "    clear_output(wait=True)\n",
    "    visualize_pipeline(original, steps, keypoints, ground_truth_points,\n",
    "                      detected_count, gt_count, mae, blob_params)\n",
    "\n",
    "\n",
    "# Create interactive widgets\n",
    "if image_files:\n",
    "    # Create widget layout\n",
    "    style = {'description_width': '180px'}\n",
    "    layout = widgets.Layout(width='500px')\n",
    "\n",
    "    interactive_widget = interactive(\n",
    "        interactive_pipeline,\n",
    "        image_file=widgets.Dropdown(\n",
    "            options=image_files,\n",
    "            value=image_files[0],\n",
    "            description='Image:',\n",
    "            style=style,\n",
    "            layout=layout\n",
    "        ),\n",
    "        gamma=widgets.FloatSlider(\n",
    "            value=0.4,\n",
    "            min=0.1,\n",
    "            max=1.0,\n",
    "            step=0.05,\n",
    "            description='Gamma:',\n",
    "            style=style,\n",
    "            layout=layout,\n",
    "            continuous_update=False\n",
    "        ),\n",
    "        clahe_clip=widgets.FloatSlider(\n",
    "            value=2.0,\n",
    "            min=0.5,\n",
    "            max=5.0,\n",
    "            step=0.5,\n",
    "            description='CLAHE Clip:',\n",
    "            style=style,\n",
    "            layout=layout,\n",
    "            continuous_update=False\n",
    "        ),\n",
    "        gaussian_size=widgets.IntSlider(\n",
    "            value=5,\n",
    "            min=1,\n",
    "            max=15,\n",
    "            step=2,\n",
    "            description='Gaussian Size:',\n",
    "            style=style,\n",
    "            layout=layout,\n",
    "            continuous_update=False\n",
    "        ),\n",
    "        top_mask_percent=widgets.FloatSlider(\n",
    "            value=0.40,\n",
    "            min=0.0,\n",
    "            max=0.8,\n",
    "            step=0.05,\n",
    "            description='Top Mask %:',\n",
    "            style=style,\n",
    "            layout=layout,\n",
    "            continuous_update=False\n",
    "        ),\n",
    "        hsv_s_max=widgets.IntSlider(\n",
    "            value=50,\n",
    "            min=0,\n",
    "            max=255,\n",
    "            step=5,\n",
    "            description='HSV S Max (Sand):',\n",
    "            style=style,\n",
    "            layout=layout,\n",
    "            continuous_update=False\n",
    "        ),\n",
    "        hsv_v_min=widgets.IntSlider(\n",
    "            value=100,\n",
    "            min=0,\n",
    "            max=255,\n",
    "            step=5,\n",
    "            description='HSV V Min (Sand):',\n",
    "            style=style,\n",
    "            layout=layout,\n",
    "            continuous_update=False\n",
    "        ),\n",
    "        morph_size=widgets.IntSlider(\n",
    "            value=5,\n",
    "            min=1,\n",
    "            max=15,\n",
    "            step=2,\n",
    "            description='Morph Size:',\n",
    "            style=style,\n",
    "            layout=layout,\n",
    "            continuous_update=False\n",
    "        ),\n",
    "        adaptive_block_size=widgets.IntSlider(\n",
    "            value=11,\n",
    "            min=3,\n",
    "            max=51,\n",
    "            step=2,\n",
    "            description='Adaptive Block:',\n",
    "            style=style,\n",
    "            layout=layout,\n",
    "            continuous_update=False\n",
    "        ),\n",
    "        adaptive_c=widgets.IntSlider(\n",
    "            value=2,\n",
    "            min=-10,\n",
    "            max=10,\n",
    "            step=1,\n",
    "            description='Adaptive C:',\n",
    "            style=style,\n",
    "            layout=layout,\n",
    "            continuous_update=False\n",
    "        ),\n",
    "        # Blob detection parameters\n",
    "        min_area=widgets.IntSlider(\n",
    "            value=300,\n",
    "            min=10,\n",
    "            max=1000,\n",
    "            step=10,\n",
    "            description='Blob Min Area:',\n",
    "            style=style,\n",
    "            layout=layout,\n",
    "            continuous_update=False\n",
    "        ),\n",
    "        max_area=widgets.IntSlider(\n",
    "            value=4500,\n",
    "            min=500,\n",
    "            max=10000,\n",
    "            step=100,\n",
    "            description='Blob Max Area:',\n",
    "            style=style,\n",
    "            layout=layout,\n",
    "            continuous_update=False\n",
    "        ),\n",
    "        min_circularity=widgets.FloatSlider(\n",
    "            value=0.2,\n",
    "            min=0.0,\n",
    "            max=1.0,\n",
    "            step=0.01,\n",
    "            description='Blob Min Circularity:',\n",
    "            style=style,\n",
    "            layout=layout,\n",
    "            continuous_update=False\n",
    "        ),\n",
    "        min_convexity=widgets.FloatSlider(\n",
    "            value=0.5,\n",
    "            min=0.0,\n",
    "            max=1.0,\n",
    "            step=0.01,\n",
    "            description='Blob Min Convexity:',\n",
    "            style=style,\n",
    "            layout=layout,\n",
    "            continuous_update=False\n",
    "        ),\n",
    "        min_inertia=widgets.FloatSlider(\n",
    "            value=0.1,\n",
    "            min=0.0,\n",
    "            max=1.0,\n",
    "            step=0.01,\n",
    "            description='Blob Min Inertia:',\n",
    "            style=style,\n",
    "            layout=layout,\n",
    "            continuous_update=False\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Display the interactive widget\n",
    "    display(interactive_widget)\n",
    "else:\n",
    "    print(\"⚠ No images found. Please check the IMAGES_DIR path and ensure it contains images.\")"
   ],
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot find widget or abbreviation for argument: 'dark_threshold'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[18]\u001B[39m\u001B[32m, line 67\u001B[39m\n\u001B[32m     64\u001B[39m style = {\u001B[33m'\u001B[39m\u001B[33mdescription_width\u001B[39m\u001B[33m'\u001B[39m: \u001B[33m'\u001B[39m\u001B[33m180px\u001B[39m\u001B[33m'\u001B[39m}\n\u001B[32m     65\u001B[39m layout = widgets.Layout(width=\u001B[33m'\u001B[39m\u001B[33m500px\u001B[39m\u001B[33m'\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m67\u001B[39m interactive_widget = \u001B[43minteractive\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     68\u001B[39m \u001B[43m    \u001B[49m\u001B[43minteractive_pipeline\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     69\u001B[39m \u001B[43m    \u001B[49m\u001B[43mimage_file\u001B[49m\u001B[43m=\u001B[49m\u001B[43mwidgets\u001B[49m\u001B[43m.\u001B[49m\u001B[43mDropdown\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     70\u001B[39m \u001B[43m        \u001B[49m\u001B[43moptions\u001B[49m\u001B[43m=\u001B[49m\u001B[43mimage_files\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     71\u001B[39m \u001B[43m        \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m=\u001B[49m\u001B[43mimage_files\u001B[49m\u001B[43m[\u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     72\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdescription\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mImage:\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     73\u001B[39m \u001B[43m        \u001B[49m\u001B[43mstyle\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstyle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     74\u001B[39m \u001B[43m        \u001B[49m\u001B[43mlayout\u001B[49m\u001B[43m=\u001B[49m\u001B[43mlayout\u001B[49m\n\u001B[32m     75\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     76\u001B[39m \u001B[43m    \u001B[49m\u001B[43mgamma\u001B[49m\u001B[43m=\u001B[49m\u001B[43mwidgets\u001B[49m\u001B[43m.\u001B[49m\u001B[43mFloatSlider\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     77\u001B[39m \u001B[43m        \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m0.4\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     78\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mmin\u001B[39;49m\u001B[43m=\u001B[49m\u001B[32;43m0.1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     79\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mmax\u001B[39;49m\u001B[43m=\u001B[49m\u001B[32;43m1.0\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     80\u001B[39m \u001B[43m        \u001B[49m\u001B[43mstep\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m0.05\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     81\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdescription\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mGamma:\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     82\u001B[39m \u001B[43m        \u001B[49m\u001B[43mstyle\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstyle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     83\u001B[39m \u001B[43m        \u001B[49m\u001B[43mlayout\u001B[49m\u001B[43m=\u001B[49m\u001B[43mlayout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     84\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcontinuous_update\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\n\u001B[32m     85\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     86\u001B[39m \u001B[43m    \u001B[49m\u001B[43mclahe_clip\u001B[49m\u001B[43m=\u001B[49m\u001B[43mwidgets\u001B[49m\u001B[43m.\u001B[49m\u001B[43mFloatSlider\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     87\u001B[39m \u001B[43m        \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m2.0\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     88\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mmin\u001B[39;49m\u001B[43m=\u001B[49m\u001B[32;43m0.5\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     89\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mmax\u001B[39;49m\u001B[43m=\u001B[49m\u001B[32;43m5.0\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     90\u001B[39m \u001B[43m        \u001B[49m\u001B[43mstep\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m0.5\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     91\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdescription\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mCLAHE Clip:\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     92\u001B[39m \u001B[43m        \u001B[49m\u001B[43mstyle\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstyle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     93\u001B[39m \u001B[43m        \u001B[49m\u001B[43mlayout\u001B[49m\u001B[43m=\u001B[49m\u001B[43mlayout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     94\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcontinuous_update\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\n\u001B[32m     95\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     96\u001B[39m \u001B[43m    \u001B[49m\u001B[43mgaussian_size\u001B[49m\u001B[43m=\u001B[49m\u001B[43mwidgets\u001B[49m\u001B[43m.\u001B[49m\u001B[43mIntSlider\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     97\u001B[39m \u001B[43m        \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m5\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     98\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mmin\u001B[39;49m\u001B[43m=\u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     99\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mmax\u001B[39;49m\u001B[43m=\u001B[49m\u001B[32;43m15\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    100\u001B[39m \u001B[43m        \u001B[49m\u001B[43mstep\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m2\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    101\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdescription\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mGaussian Size:\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    102\u001B[39m \u001B[43m        \u001B[49m\u001B[43mstyle\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstyle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    103\u001B[39m \u001B[43m        \u001B[49m\u001B[43mlayout\u001B[49m\u001B[43m=\u001B[49m\u001B[43mlayout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    104\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcontinuous_update\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\n\u001B[32m    105\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    106\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtop_mask_percent\u001B[49m\u001B[43m=\u001B[49m\u001B[43mwidgets\u001B[49m\u001B[43m.\u001B[49m\u001B[43mFloatSlider\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    107\u001B[39m \u001B[43m        \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m0.40\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    108\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mmin\u001B[39;49m\u001B[43m=\u001B[49m\u001B[32;43m0.0\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    109\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mmax\u001B[39;49m\u001B[43m=\u001B[49m\u001B[32;43m0.8\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    110\u001B[39m \u001B[43m        \u001B[49m\u001B[43mstep\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m0.05\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    111\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdescription\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mTop Mask \u001B[39;49m\u001B[33;43m%\u001B[39;49m\u001B[33;43m:\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    112\u001B[39m \u001B[43m        \u001B[49m\u001B[43mstyle\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstyle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    113\u001B[39m \u001B[43m        \u001B[49m\u001B[43mlayout\u001B[49m\u001B[43m=\u001B[49m\u001B[43mlayout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    114\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcontinuous_update\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\n\u001B[32m    115\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    116\u001B[39m \u001B[43m    \u001B[49m\u001B[43mhsv_s_max\u001B[49m\u001B[43m=\u001B[49m\u001B[43mwidgets\u001B[49m\u001B[43m.\u001B[49m\u001B[43mIntSlider\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    117\u001B[39m \u001B[43m        \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m50\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    118\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mmin\u001B[39;49m\u001B[43m=\u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    119\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mmax\u001B[39;49m\u001B[43m=\u001B[49m\u001B[32;43m255\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    120\u001B[39m \u001B[43m        \u001B[49m\u001B[43mstep\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m5\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    121\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdescription\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mHSV S Max (Sand):\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    122\u001B[39m \u001B[43m        \u001B[49m\u001B[43mstyle\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstyle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    123\u001B[39m \u001B[43m        \u001B[49m\u001B[43mlayout\u001B[49m\u001B[43m=\u001B[49m\u001B[43mlayout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    124\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcontinuous_update\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\n\u001B[32m    125\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    126\u001B[39m \u001B[43m    \u001B[49m\u001B[43mhsv_v_min\u001B[49m\u001B[43m=\u001B[49m\u001B[43mwidgets\u001B[49m\u001B[43m.\u001B[49m\u001B[43mIntSlider\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    127\u001B[39m \u001B[43m        \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m100\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    128\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mmin\u001B[39;49m\u001B[43m=\u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    129\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mmax\u001B[39;49m\u001B[43m=\u001B[49m\u001B[32;43m255\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    130\u001B[39m \u001B[43m        \u001B[49m\u001B[43mstep\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m5\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    131\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdescription\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mHSV V Min (Sand):\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    132\u001B[39m \u001B[43m        \u001B[49m\u001B[43mstyle\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstyle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    133\u001B[39m \u001B[43m        \u001B[49m\u001B[43mlayout\u001B[49m\u001B[43m=\u001B[49m\u001B[43mlayout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    134\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcontinuous_update\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\n\u001B[32m    135\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    136\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmorph_size\u001B[49m\u001B[43m=\u001B[49m\u001B[43mwidgets\u001B[49m\u001B[43m.\u001B[49m\u001B[43mIntSlider\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    137\u001B[39m \u001B[43m        \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m5\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    138\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mmin\u001B[39;49m\u001B[43m=\u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    139\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mmax\u001B[39;49m\u001B[43m=\u001B[49m\u001B[32;43m15\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    140\u001B[39m \u001B[43m        \u001B[49m\u001B[43mstep\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m2\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    141\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdescription\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mMorph Size:\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    142\u001B[39m \u001B[43m        \u001B[49m\u001B[43mstyle\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstyle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    143\u001B[39m \u001B[43m        \u001B[49m\u001B[43mlayout\u001B[49m\u001B[43m=\u001B[49m\u001B[43mlayout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    144\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcontinuous_update\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\n\u001B[32m    145\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    146\u001B[39m \u001B[43m    \u001B[49m\u001B[43madaptive_block_size\u001B[49m\u001B[43m=\u001B[49m\u001B[43mwidgets\u001B[49m\u001B[43m.\u001B[49m\u001B[43mIntSlider\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    147\u001B[39m \u001B[43m        \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m11\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    148\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mmin\u001B[39;49m\u001B[43m=\u001B[49m\u001B[32;43m3\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    149\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mmax\u001B[39;49m\u001B[43m=\u001B[49m\u001B[32;43m51\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    150\u001B[39m \u001B[43m        \u001B[49m\u001B[43mstep\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m2\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    151\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdescription\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mAdaptive Block:\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    152\u001B[39m \u001B[43m        \u001B[49m\u001B[43mstyle\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstyle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    153\u001B[39m \u001B[43m        \u001B[49m\u001B[43mlayout\u001B[49m\u001B[43m=\u001B[49m\u001B[43mlayout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    154\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcontinuous_update\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\n\u001B[32m    155\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    156\u001B[39m \u001B[43m    \u001B[49m\u001B[43madaptive_c\u001B[49m\u001B[43m=\u001B[49m\u001B[43mwidgets\u001B[49m\u001B[43m.\u001B[49m\u001B[43mIntSlider\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    157\u001B[39m \u001B[43m        \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m2\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    158\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mmin\u001B[39;49m\u001B[43m=\u001B[49m\u001B[43m-\u001B[49m\u001B[32;43m10\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    159\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mmax\u001B[39;49m\u001B[43m=\u001B[49m\u001B[32;43m10\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    160\u001B[39m \u001B[43m        \u001B[49m\u001B[43mstep\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    161\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdescription\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mAdaptive C:\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    162\u001B[39m \u001B[43m        \u001B[49m\u001B[43mstyle\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstyle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    163\u001B[39m \u001B[43m        \u001B[49m\u001B[43mlayout\u001B[49m\u001B[43m=\u001B[49m\u001B[43mlayout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    164\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcontinuous_update\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\n\u001B[32m    165\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    166\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# Blob detection parameters\u001B[39;49;00m\n\u001B[32m    167\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmin_area\u001B[49m\u001B[43m=\u001B[49m\u001B[43mwidgets\u001B[49m\u001B[43m.\u001B[49m\u001B[43mIntSlider\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    168\u001B[39m \u001B[43m        \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m300\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    169\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mmin\u001B[39;49m\u001B[43m=\u001B[49m\u001B[32;43m10\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    170\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mmax\u001B[39;49m\u001B[43m=\u001B[49m\u001B[32;43m1000\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    171\u001B[39m \u001B[43m        \u001B[49m\u001B[43mstep\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m10\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    172\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdescription\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mBlob Min Area:\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    173\u001B[39m \u001B[43m        \u001B[49m\u001B[43mstyle\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstyle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    174\u001B[39m \u001B[43m        \u001B[49m\u001B[43mlayout\u001B[49m\u001B[43m=\u001B[49m\u001B[43mlayout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    175\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcontinuous_update\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\n\u001B[32m    176\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    177\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmax_area\u001B[49m\u001B[43m=\u001B[49m\u001B[43mwidgets\u001B[49m\u001B[43m.\u001B[49m\u001B[43mIntSlider\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    178\u001B[39m \u001B[43m        \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m4500\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    179\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mmin\u001B[39;49m\u001B[43m=\u001B[49m\u001B[32;43m500\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    180\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mmax\u001B[39;49m\u001B[43m=\u001B[49m\u001B[32;43m10000\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    181\u001B[39m \u001B[43m        \u001B[49m\u001B[43mstep\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m100\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    182\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdescription\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mBlob Max Area:\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    183\u001B[39m \u001B[43m        \u001B[49m\u001B[43mstyle\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstyle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    184\u001B[39m \u001B[43m        \u001B[49m\u001B[43mlayout\u001B[49m\u001B[43m=\u001B[49m\u001B[43mlayout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    185\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcontinuous_update\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\n\u001B[32m    186\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    187\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmin_circularity\u001B[49m\u001B[43m=\u001B[49m\u001B[43mwidgets\u001B[49m\u001B[43m.\u001B[49m\u001B[43mFloatSlider\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    188\u001B[39m \u001B[43m        \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m0.2\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    189\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mmin\u001B[39;49m\u001B[43m=\u001B[49m\u001B[32;43m0.0\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    190\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mmax\u001B[39;49m\u001B[43m=\u001B[49m\u001B[32;43m1.0\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    191\u001B[39m \u001B[43m        \u001B[49m\u001B[43mstep\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m0.01\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    192\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdescription\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mBlob Min Circularity:\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    193\u001B[39m \u001B[43m        \u001B[49m\u001B[43mstyle\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstyle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    194\u001B[39m \u001B[43m        \u001B[49m\u001B[43mlayout\u001B[49m\u001B[43m=\u001B[49m\u001B[43mlayout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    195\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcontinuous_update\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\n\u001B[32m    196\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    197\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmin_convexity\u001B[49m\u001B[43m=\u001B[49m\u001B[43mwidgets\u001B[49m\u001B[43m.\u001B[49m\u001B[43mFloatSlider\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    198\u001B[39m \u001B[43m        \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m0.5\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    199\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mmin\u001B[39;49m\u001B[43m=\u001B[49m\u001B[32;43m0.0\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    200\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mmax\u001B[39;49m\u001B[43m=\u001B[49m\u001B[32;43m1.0\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    201\u001B[39m \u001B[43m        \u001B[49m\u001B[43mstep\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m0.01\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    202\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdescription\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mBlob Min Convexity:\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    203\u001B[39m \u001B[43m        \u001B[49m\u001B[43mstyle\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstyle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    204\u001B[39m \u001B[43m        \u001B[49m\u001B[43mlayout\u001B[49m\u001B[43m=\u001B[49m\u001B[43mlayout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    205\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcontinuous_update\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\n\u001B[32m    206\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    207\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmin_inertia\u001B[49m\u001B[43m=\u001B[49m\u001B[43mwidgets\u001B[49m\u001B[43m.\u001B[49m\u001B[43mFloatSlider\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    208\u001B[39m \u001B[43m        \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m0.1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    209\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mmin\u001B[39;49m\u001B[43m=\u001B[49m\u001B[32;43m0.0\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    210\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mmax\u001B[39;49m\u001B[43m=\u001B[49m\u001B[32;43m1.0\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    211\u001B[39m \u001B[43m        \u001B[49m\u001B[43mstep\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m0.01\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    212\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdescription\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mBlob Min Inertia:\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    213\u001B[39m \u001B[43m        \u001B[49m\u001B[43mstyle\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstyle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    214\u001B[39m \u001B[43m        \u001B[49m\u001B[43mlayout\u001B[49m\u001B[43m=\u001B[49m\u001B[43mlayout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    215\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcontinuous_update\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\n\u001B[32m    216\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    217\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    219\u001B[39m \u001B[38;5;66;03m# Display the interactive widget\u001B[39;00m\n\u001B[32m    220\u001B[39m display(interactive_widget)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/master_activities/video_analysis/project1/.venv/lib/python3.13/site-packages/ipywidgets/widgets/interaction.py:175\u001B[39m, in \u001B[36minteractive.__init__\u001B[39m\u001B[34m(self, _interactive__interact_f, _interactive__options, **kwargs)\u001B[39m\n\u001B[32m    172\u001B[39m \u001B[38;5;28mself\u001B[39m.manual_name = __options.get(\u001B[33m\"\u001B[39m\u001B[33mmanual_name\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mRun Interact\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m    173\u001B[39m \u001B[38;5;28mself\u001B[39m.auto_display = __options.get(\u001B[33m\"\u001B[39m\u001B[33mauto_display\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[32m--> \u001B[39m\u001B[32m175\u001B[39m new_kwargs = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mfind_abbreviations\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    176\u001B[39m \u001B[38;5;66;03m# Before we proceed, let's make sure that the user has passed a set of args+kwargs\u001B[39;00m\n\u001B[32m    177\u001B[39m \u001B[38;5;66;03m# that will lead to a valid call of the function. This protects against unspecified\u001B[39;00m\n\u001B[32m    178\u001B[39m \u001B[38;5;66;03m# and doubly-specified arguments.\u001B[39;00m\n\u001B[32m    179\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/master_activities/video_analysis/project1/.venv/lib/python3.13/site-packages/ipywidgets/widgets/interaction.py:275\u001B[39m, in \u001B[36minteractive.find_abbreviations\u001B[39m\u001B[34m(self, kwargs)\u001B[39m\n\u001B[32m    273\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m name, value, default \u001B[38;5;129;01min\u001B[39;00m _yield_abbreviations_for_parameter(param, kwargs):\n\u001B[32m    274\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m value \u001B[38;5;129;01mis\u001B[39;00m empty:\n\u001B[32m--> \u001B[39m\u001B[32m275\u001B[39m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[33m'\u001B[39m\u001B[33mcannot find widget or abbreviation for argument: \u001B[39m\u001B[38;5;132;01m{!r}\u001B[39;00m\u001B[33m'\u001B[39m.format(name))\n\u001B[32m    276\u001B[39m         new_kwargs.append((name, value, default))\n\u001B[32m    277\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m new_kwargs\n",
      "\u001B[31mValueError\u001B[39m: cannot find widget or abbreviation for argument: 'dark_threshold'"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Batch Processing (Optional)\n",
    "\n",
    "Process all images with current parameters and generate a summary report."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T09:05:25.378379Z",
     "start_time": "2025-12-11T08:16:05.836809Z"
    }
   },
   "source": [
    "def batch_process_images(gamma=0.4, clahe_clip=2.0, gaussian_size=5,\n",
    "                        top_mask_percent=0.40, hsv_s_max=50, hsv_v_min=100,\n",
    "                        morph_size=5, adaptive_block_size=11, adaptive_c=2, dark_threshold=30,\n",
    "                        min_area=300, max_area=4500, min_circularity=0.2,\n",
    "                        min_convexity=0.5, min_inertia=0.1):\n",
    "    \"\"\"Process all images with specified parameters.\"\"\"\n",
    "    \n",
    "    if not image_files:\n",
    "        print(\"⚠ No images available.\")\n",
    "        return\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    print(f\"Processing {len(image_files)} images...\\n\")\n",
    "    print(f\"{'Image':<20} {'GT':>6} {'Detected':>10} {'MAE':>6} {'Error%':>8}\")\n",
    "    print(\"-\" * 55)\n",
    "    \n",
    "    total_gt = 0\n",
    "    total_detected = 0\n",
    "    total_mae = 0\n",
    "    \n",
    "    for image_file in image_files:\n",
    "        # Load and process image\n",
    "        image_path = os.path.join(IMAGES_DIR, image_file)\n",
    "        original = load_image(image_path)\n",
    "        image_name = Path(image_file).stem\n",
    "        \n",
    "        # Get ground truth\n",
    "        ground_truth_points = get_ground_truth(annotations_df, image_name)\n",
    "        gt_count = len(ground_truth_points)\n",
    "        \n",
    "        # Process\n",
    "        clahe_rgb, _ = apply_clahe(original, clahe_clip)\n",
    "        steps = apply_preprocessing(\n",
    "            clahe_rgb, gamma=gamma, gaussian_size=gaussian_size,\n",
    "            top_mask_percent=top_mask_percent, hsv_s_max=hsv_s_max,\n",
    "            hsv_v_min=hsv_v_min, morph_size=morph_size,\n",
    "            adaptive_block_size=adaptive_block_size, adaptive_c=adaptive_c,\n",
    "            dark_threshold=dark_threshold\n",
    "        )\n",
    "        \n",
    "        keypoints, _ = detect_blobs(\n",
    "            steps['binary'],\n",
    "            min_area=min_area,\n",
    "            max_area=max_area,\n",
    "            min_circularity=min_circularity,\n",
    "            min_convexity=min_convexity,\n",
    "            min_inertia=min_inertia\n",
    "        )\n",
    "        detected_count = len(keypoints)\n",
    "        \n",
    "        mae = calculate_mae(detected_count, gt_count)\n",
    "        error_pct = (mae / gt_count * 100) if gt_count > 0 else 0\n",
    "        \n",
    "        results.append({\n",
    "            'image': image_name,\n",
    "            'gt_count': gt_count,\n",
    "            'detected': detected_count,\n",
    "            'mae': mae,\n",
    "            'error_pct': error_pct\n",
    "        })\n",
    "        \n",
    "        print(f\"{image_name:<20} {gt_count:>6} {detected_count:>10} {mae:>6} {error_pct:>7.1f}%\")\n",
    "        \n",
    "        total_gt += gt_count\n",
    "        total_detected += detected_count\n",
    "        total_mae += mae\n",
    "    \n",
    "    print(\"-\" * 55)\n",
    "    print(f\"{'TOTAL':<20} {total_gt:>6} {total_detected:>10} {total_mae:>6}\")\n",
    "    avg_mae = total_mae / len(image_files) if image_files else 0\n",
    "    print(f\"{'AVERAGE MAE':<20} {avg_mae:>6.2f}\")\n",
    "    \n",
    "    # Create summary visualization\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # Chart 1: MAE per image\n",
    "    images = [r['image'][:12] for r in results]\n",
    "    maes = [r['mae'] for r in results]\n",
    "    \n",
    "    ax1.bar(range(len(images)), maes, color='coral', alpha=0.7)\n",
    "    ax1.set_xlabel('Image', fontweight='bold')\n",
    "    ax1.set_ylabel('MAE', fontweight='bold')\n",
    "    ax1.set_title('MAE per Image', fontweight='bold', fontsize=14)\n",
    "    ax1.set_xticks(range(len(images)))\n",
    "    ax1.set_xticklabels(images, rotation=45, ha='right')\n",
    "    ax1.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Chart 2: GT vs Detected\n",
    "    gt_counts = [r['gt_count'] for r in results]\n",
    "    detected_counts = [r['detected'] for r in results]\n",
    "    \n",
    "    x = range(len(images))\n",
    "    width = 0.35\n",
    "    \n",
    "    ax2.bar([i - width/2 for i in x], gt_counts, width, label='Ground Truth', \n",
    "            color='red', alpha=0.7)\n",
    "    ax2.bar([i + width/2 for i in x], detected_counts, width, label='Detected', \n",
    "            color='green', alpha=0.7)\n",
    "    \n",
    "    ax2.set_xlabel('Image', fontweight='bold')\n",
    "    ax2.set_ylabel('Count', fontweight='bold')\n",
    "    ax2.set_title('Ground Truth vs Detected', fontweight='bold', fontsize=14)\n",
    "    ax2.set_xticks(x)\n",
    "    ax2.set_xticklabels(images, rotation=45, ha='right')\n",
    "    ax2.legend()\n",
    "    ax2.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "# Uncomment to run batch processing with current parameters\n",
    "# results = batch_process_images(\n",
    "#     gamma=0.4,\n",
    "#     clahe_clip=2.0,\n",
    "#     gaussian_size=5,\n",
    "#     top_mask_percent=0.40,\n",
    "#     hsv_s_max=50,\n",
    "#     hsv_v_min=100,\n",
    "#     morph_size=5,\n",
    "#     adaptive_block_size=11,\n",
    "#     adaptive_c=2,\n",
    "#     dark_threshold=30,\n",
    "#     min_area=300,\n",
    "#     max_area=4500,\n",
    "#     min_circularity=0.2,\n",
    "#     min_convexity=0.5,\n",
    "#     min_inertia=0.1\n",
    "# )"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Export Best Parameters\n",
    "\n",
    "Save your optimized parameters for later use."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T09:05:25.379021Z",
     "start_time": "2025-12-11T08:16:05.844254Z"
    }
   },
   "source": [
    "def save_parameters(filename='best_parameters.json', **params):\n",
    "    \"\"\"Save parameters to JSON file.\"\"\"\n",
    "    import json\n",
    "    \n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(params, f, indent=2)\n",
    "    \n",
    "    print(f\"✓ Parameters saved to {filename}\")\n",
    "    print(json.dumps(params, indent=2))\n",
    "\n",
    "\n",
    "# Example usage - update with your best parameters:\n",
    "# save_parameters(\n",
    "#     filename='best_parameters.json',\n",
    "#     gamma=0.4,\n",
    "#     clahe_clip=2.0,\n",
    "#     gaussian_size=5,\n",
    "#     top_mask_percent=0.40,\n",
    "#     hsv_s_max=50,\n",
    "#     hsv_v_min=100,\n",
    "#     morph_size=5,\n",
    "#     adaptive_block_size=11,\n",
    "#     adaptive_c=2,\n",
    "#     min_area=300,\n",
    "#     max_area=4500,\n",
    "#     min_circularity=0.2,\n",
    "#     min_convexity=0.5,\n",
    "#     min_inertia=0.1\n",
    "# )"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "### Getting Started:\n",
    "1. **Update paths** in cell 6 to point to your images directory and annotations CSV\n",
    "2. **Run all cells** (Cell → Run All)\n",
    "3. **Use the interactive sliders** in cell 7 to tune parameters\n",
    "\n",
    "### Parameter Guide:\n",
    "\n",
    "#### Preprocessing Parameters:\n",
    "- **Gamma** (0.1-1.0): Brightness adjustment. Lower values brighten the image.\n",
    "- **CLAHE Clip** (0.5-5.0): Contrast enhancement limit.\n",
    "- **Gaussian Size** (1-15): Smoothing kernel size (must be odd).\n",
    "- **Top Mask %** (0-0.8): Portion of top image to mask out.\n",
    "- **Dark Threshold** (0-255): Remove pixels darker than this value. Filters out shadows, dark rocks, and dark objects that aren't people. Higher values = more aggressive filtering.\n",
    "- **HSV S Max** (0-255): Maximum saturation for sand detection (lower = less colorful).\n",
    "- **HSV V Min** (0-255): Minimum brightness for sand detection (higher = brighter).\n",
    "- **Morph Size** (1-15): Morphological operation kernel size.\n",
    "- **Adaptive Block** (3-51): Adaptive threshold block size (must be odd).\n",
    "- **Adaptive C** (-10 to 10): Adaptive threshold constant.\n",
    "\n",
    "#### Blob Detection Parameters (Direct Control):\n",
    "- **Min Area** (10-1000): Minimum blob size in pixels. Smaller = detect smaller objects.\n",
    "- **Max Area** (500-10000): Maximum blob size in pixels. Larger = allow bigger objects.\n",
    "- **Min Circularity** (0.0-1.0): How round the blob must be (1.0 = perfect circle).\n",
    "- **Min Convexity** (0.0-1.0): How convex the blob must be (1.0 = perfectly convex).\n",
    "- **Min Inertia** (0.0-1.0): How elongated the blob can be (higher = more round).\n",
    "\n",
    "### New Visualizations:\n",
    "- **Sand Mask**: Shows detected sand regions (where people should be)\n",
    "- **Non-Sand Mask**: Shows filtered out regions (not sand)\n",
    "- **HSV Histogram**: Analyze color distribution to tune HSV S Max and V Min\n",
    "- **LAB Histogram**: Additional color space analysis\n",
    "\n",
    "### Tips:\n",
    "- Start with default values and adjust one parameter at a time\n",
    "- Use HSV histogram (cell 8) to understand sand color characteristics\n",
    "- Watch the sand mask to ensure you're selecting the right regions\n",
    "- Lower circularity/convexity/inertia = more lenient blob detection\n",
    "- Watch the MAE (Mean Absolute Error) - lower is better\n",
    "- Red circles = Ground truth, Green circles = Detected\n",
    "- Use batch processing (cell 10) once you find good parameters\n",
    "- Save your best parameters using cell 11"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
